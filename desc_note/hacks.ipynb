{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hideme"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cPickle as cpkl\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hideme"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# print(mpl.rcParams.items)\n",
    "mpl.use('Agg')\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "mpl.rcParams['mathtext.rm'] = 'serif'\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['font.serif'] = ['Times New Roman']\n",
    "# mpl.rcParams['font.family'] = ['Times New Roman']\n",
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 14\n",
    "mpl.rcParams['savefig.dpi'] = 250\n",
    "mpl.rcParams['figure.dpi'] = 250\n",
    "mpl.rcParams['savefig.format'] = 'pdf'\n",
    "mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# print(mpl.rcParams.items)\n",
    "\n",
    "import pylab\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hideme"
    ]
   },
   "outputs": [],
   "source": [
    "import proclam\n",
    "from proclam import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hideme"
    ]
   },
   "outputs": [],
   "source": [
    "M_classes = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_objects = 100000\n",
    "generator = proclam.simulators.LogUnbalanced()\n",
    "minitruth = generator.simulate(M_classes, N_objects)\n",
    "pops = np.histogram(minitruth, bins=range(M_classes+1))[0]\n",
    "# print(pops)\n",
    "minipops = np.empty(M_classes)\n",
    "for m in range(M_classes):\n",
    "    minipops[m] = np.log10(np.max((pops[m], 1.))) /np.log10(N_objects)# / M_classes\n",
    "# print(np.log10(minipops) / np.log10(N_objects))\n",
    "# print(np.sum(minipops) / M_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hidein"
    ]
   },
   "outputs": [],
   "source": [
    "truth = minitruth\n",
    "d = np.diff(np.unique(truth)).min()\n",
    "left_of_first_bin = truth.min() - float(d)/2\n",
    "right_of_last_bin = truth.max() + float(d)/2\n",
    "plt.hist(truth, np.arange(left_of_first_bin, right_of_last_bin + d, d), log=True, alpha=0.5, color='k')\n",
    "plt.xticks(range(max(truth)+1))\n",
    "# plt.hist(truth, log=True, alpha=0.5)\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('class')\n",
    "plt.savefig('fig/complete_counts.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first, when the systematics are added to almost perfect classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = proclam.classifiers.FromCM()\n",
    "\n",
    "minitest = {}\n",
    "which_affected = range(M_classes)\n",
    "systematic_info = {'agnostic':'s', 'tunnel':'o', 'almost':'P', 'noisy':'X', 'cruise':'d', 'subsumed':(3,0,0)}\n",
    "which_systematics = systematic_info.keys()#['agnostic', 'tunnel', 'almost', 'noisy', 'tunnel', 'cruise', 'subsumed']\n",
    "markerlist = systematic_info.values()#['', '', 'd', 'o', 'd', 's', (3,0,0)]\n",
    "\n",
    "minidelta = 0.1\n",
    "starter = np.eye(M_classes) + minidelta * np.ones((M_classes, M_classes))\n",
    "starter = starter / np.sum(starter, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cm(start_cm, m, systematic):\n",
    "    # can wrap this in loop if systematic is a list\n",
    "    cm = start_cm\n",
    "    big_M = len(start_cm)\n",
    "    if systematic == 'agnostic':\n",
    "        cm[m] = np.ones(big_M)\n",
    "    if systematic == 'almost':\n",
    "        cm[m] = 0.5 * np.ones(big_M)\n",
    "        cm[m][m] += 1.5\n",
    "    if systematic == 'noisy':\n",
    "        cm[m] = 0.5 * np.ones(big_M)\n",
    "        cm[m][m] += 0.5\n",
    "    if systematic == 'tunnel' or systematic == 'perfect':\n",
    "        cm[m] = np.zeros(big_M)\n",
    "        cm[:, m] = np.zeros(big_M).T\n",
    "        cm[m][m] += 1.\n",
    "    if systematic == 'cruise' or systematic == 'subsumer':\n",
    "        cm[:, m] += 1.\n",
    "    if systematic == 'subsumed':\n",
    "        cm[m] = cm[m-1]\n",
    "    cm = cm / np.sum(cm, axis=1)[:, np.newaxis]\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_weighted = ['by pop', 'flat', 'up', 'down']\n",
    "wt_colors = [mpl.cm.winter_r(minipops), [mpl.cm.autumn_r(0.5)]*M_classes, [mpl.cm.autumn_r(1.)]*M_classes, [mpl.cm.autumn_r(0.)]*M_classes]\n",
    "wt_const = 1. / float(M_classes)\n",
    "    \n",
    "which_metrics = ['Brier', 'LogLoss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wv(m, wt_kw):\n",
    "#     wv = np.ones(M_classes)\n",
    "    if wt_kw == 'by pop':\n",
    "        wv = minipops\n",
    "    if wt_kw == 'flat': \n",
    "        wv = np.ones(M_classes)\n",
    "    if wt_kw == 'up':\n",
    "        wv = np.ones(M_classes)\n",
    "        wv[m] += 1.\n",
    "    if wt_kw == 'down':\n",
    "        wv = np.ones(M_classes)\n",
    "        wv[m] /= 2.\n",
    "    wv = wv / np.sum(wv)\n",
    "    assert(np.isclose(np.sum(wv), 1.))\n",
    "    return wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniweights = np.empty((len(which_weighted), M_classes, M_classes))\n",
    "for m in which_affected:\n",
    "    for wi in range(len(which_weighted)):\n",
    "        w = which_weighted[wi]\n",
    "        miniweights[wi][m] = make_wv(m, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # warning: slow!!!\n",
    "# for s in which_systematics:\n",
    "#     minitest[s] = {}\n",
    "#     for m in which_affected:\n",
    "#         minitest[s][str(m)] = {}\n",
    "#         minitest[s][str(m)]['cm'] = make_cm(starter, m, s)\n",
    "#         minitest[s][str(m)]['probs'] = classifier.classify(minitest[s][str(m)]['cm'], minitruth, \n",
    "#                                                            delta=minidelta, other=False)\n",
    "#         minitest[s][str(m)]['results'] = {}\n",
    "#         for met in which_metrics:\n",
    "#             minitest[s][str(m)][met] = {}\n",
    "#             for wi in range(len(which_weighted)):\n",
    "#                 w = which_weighted[wi]\n",
    "#                 D = getattr(proclam.metrics, met)()\n",
    "#                 minitest[s][str(m)][met][w] = D.evaluate(minitest[s][str(m)]['probs'], minitruth, \n",
    "#                                                          averaging=miniweights[wi][m])\n",
    "#     print('finished '+s)\n",
    "#     cpkl.dump(minitest[s], open(s+'_data.pkl', 'wb'))\n",
    "#     print('saved '+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: slow!\n",
    "goodtest = {}\n",
    "for s in which_systematics:\n",
    "    goodtest[s] = cpkl.load(open(s+'_data.pkl', 'rb'))\n",
    "#     minitest[s] = cpkl.load(open('almost_'+s+'_data.pkl', 'rb'))\n",
    "    print('loaded '+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect lines along systematic, weighting, and affected class\n",
    "def complete_metric_plot(dataset, metric_names, shapes, fn=''):\n",
    "    \n",
    "    systematics = dataset.keys()\n",
    "    xs = np.arange(len(systematics))\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    \n",
    "    ax.text(0.01, 0.75, r'size$\\sim \\log[N_{m}/N]$', \n",
    "            verticalalignment='center', transform=ax.transAxes, \n",
    "            fontsize=10)\n",
    "#     ax.text(.3, .9, r'size$\\sim \\exp[w_{m}]$', \n",
    "#             verticalalignment='center', transform=ax.transAxes, \n",
    "#             fontsize=10)\n",
    "    fig.subplots_adjust(right=1.)\n",
    "#     handles = []\n",
    "#     seeds = []\n",
    "    for m in which_affected:\n",
    "#         one_seed = np.log10(max(1., N_objects * float(minipops[m]))) / 10.\n",
    "#         seeds.append(one_seed)\n",
    "        for si in range(len(systematics)):\n",
    "            s = systematics[si]\n",
    "            for wi in range(len(which_weighted)):\n",
    "                w = which_weighted[wi]\n",
    "#                 print(miniweights[wi][m][m])\n",
    "#                 rel_wt = (((miniweights[wi][m][m] - wt_const) / wt_const) + 1.) / 2.\n",
    "#                 print(rel_wt)\n",
    "                ax.scatter(dataset[s][str(m)][metric_names[0]][w], dataset[s][str(m)][metric_names[1]][w],\n",
    "                  c=wt_colors[wi][m],\n",
    "                  s=50*(0.01 + minipops[m]),#N_objects**miniweights[wi][m],#rel_wt,\n",
    "                  marker=markerlist[si],\n",
    "                  alpha=0.25)\n",
    "    for si in range(len(systematics)):\n",
    "        ax.scatter(0., 0., c='k',\n",
    "                  marker=markerlist[si],\n",
    "                  alpha=0.25, label=systematics[si])\n",
    "    \n",
    "    ax.set_xlabel(metric_names[0])\n",
    "    ax.set_ylabel(metric_names[1])\n",
    "    ax.set_ylim(0.9, 3.5)\n",
    "    ax.set_xlim(0.035, 0.09)\n",
    "    ax.legend(loc='lower right')\n",
    "    \n",
    "#     seeds = np.array(seeds)\n",
    "#     print(seeds)\n",
    "    popaxins = inset_axes(ax,\n",
    "                    width=\"25%\",  # width = 25% of parent_bbox width\n",
    "                    height=\"5%\",  # height : 5%\n",
    "                    loc=2)#bbox_to_anchor=(0.35, 0.8))\n",
    "    mpl.colorbar.ColorbarBase(popaxins, cmap=mpl.cm.winter_r,\n",
    "                                norm=mpl.colors.Normalize(vmin=0., vmax=1.), \n",
    "                              orientation='horizontal')\n",
    "#     popaxins.xaxis.set_ticks_position(\"top\")\n",
    "    popaxins.set_title(r'$w_{m}\\sim N_{m}/N$', fontsize=10)\n",
    "    popaxins.xaxis.set_ticks(np.concatenate((np.concatenate((np.zeros(1), np.flip(minipops, axis=0))), np.ones(1))))\n",
    "    popaxins.xaxis.set_ticklabels(['0']+[]*M_classes+['1'], fontsize=10) #rotation=270, fontsize=10)\n",
    "    \n",
    "    linaxins = inset_axes(ax,\n",
    "                    width=\"25%\",  # width = 25% of parent_bbox width\n",
    "                    height=\"5%\",  # height : 5%\n",
    "                    loc=6)#bbox_to_anchor=(0.35, 0.55))\n",
    "#     linaxins = axins.add_axes([0., 1.])\n",
    "    mpl.colorbar.ColorbarBase(linaxins, cmap=mpl.cm.autumn_r,\n",
    "                                norm=mpl.colors.Normalize(vmin=0., vmax=1.),#vmin=0.04, vmax=0.14285714), \n",
    "                              orientation='horizontal')\n",
    "#     linaxins.xaxis.set_ticks_position(\"top\")\n",
    "    linaxins.set_title('flat/up/down weights', fontsize=10)\n",
    "    linaxins.xaxis.set_ticks([0., 0.5, 1.])\n",
    "    linaxins.xaxis.set_ticklabels(['downweight', 'flat', 'upweight'], \n",
    "                                  rotation=270, fontsize=10)\n",
    "    \n",
    "#     plt.show()\n",
    "    plt.savefig('fig/'+fn+'all_effects_isolated.png', dpi=250)\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_metric_plot(goodtest, which_metrics, markerlist, fn='almost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## when the systematics are added to agnostic classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter = np.ones((M_classes, M_classes))\n",
    "starter = starter / np.sum(starter, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # warning: slow!!!\n",
    "# for s in which_systematics:\n",
    "#     minitest[s] = {}\n",
    "#     for m in which_affected:\n",
    "#         minitest[s][str(m)] = {}\n",
    "#         minitest[s][str(m)]['cm'] = make_cm(starter, m, s)\n",
    "#         minitest[s][str(m)]['probs'] = classifier.classify(minitest[s][str(m)]['cm'], minitruth, \n",
    "#                                                            delta=minidelta, other=False)\n",
    "#         minitest[s][str(m)]['results'] = {}\n",
    "#         for met in which_metrics:\n",
    "#             minitest[s][str(m)][met] = {}\n",
    "#             for wi in range(len(which_weighted)):\n",
    "#                 w = which_weighted[wi]\n",
    "#                 D = getattr(proclam.metrics, met)()\n",
    "#                 minitest[s][str(m)][met][w] = D.evaluate(minitest[s][str(m)]['probs'], minitruth, \n",
    "#                                                          averaging=miniweights[wi][m])\n",
    "#     print('finished '+s)\n",
    "#     cpkl.dump(minitest[s], open('agnostic_'+s+'_data.pkl', 'wb'))\n",
    "#     print('saved '+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: slow!\n",
    "badtest = {}\n",
    "for s in which_systematics:\n",
    "#     minitest[s] = cpkl.load(open(s+'_data.pkl', 'rb'))\n",
    "    badtest[s] = cpkl.load(open('agnostic_'+s+'_data.pkl', 'rb'))\n",
    "    print('loaded '+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_metric_plot(badtest, which_metrics, markerlist, fn='agnostic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would like to do this many times to generate error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hideme"
    ]
   },
   "outputs": [],
   "source": [
    "# cells with a tag of \"hideme\" will not appear in html resulting from:\n",
    "# jupyter nbconvert desc_note/main.ipynb --TagRemovePreprocessor.remove_cell_tags='[\"hideme\"]'\n",
    "# jupyter nbconvert desc_note/main.ipynb --TagRemovePreprocessor.remove_input_tags='[\"hidein\"]'\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
