{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![](./header.png) -->\n",
    "<img src=\"./header.png\",width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection of a performance metric for PLAsTiCC\n",
    "\n",
    "*Alex Malz (NYU)*, *Tarek Alam (UCL)*, *Anita Bahmanyar (U. Toronto)*, *Rahul Biswas (U. Stockholm)*, *Rafael Martinez-Galarza (Harvard)*, *Renee Hlozek (U. Toronto)*, *Gautham Narayan (STScI)*\n",
    "\n",
    "We describe and illustrate the process by which a global performance metric was chosen for Photometric LSST Astronomical Time-series Classification Challenge (PLAsTiCC), a Kaggle competition aiming to identify promising transient and variable classifiers for LSST by involving the broader community outside astronomy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "============\n",
    "\n",
    "The metric of this note is for the first version of the Kaggle competition, though there are future plans for an early classification challenge and identification of class-specific metrics for different science goals.\n",
    "\n",
    "* The metric must return a single scalar value.\n",
    "* The metric must balance diverse science use cases in the presence of heavily nonuniform class prevalence.\n",
    "* The classification results should be posterior probabilities of class given the photometric lightcurve, but the metric must also be able to evaluate deterministic classifications.\n",
    "* The metric must be interpretable, meaning it gives a more optimal value for \"good\" mock classifiers and a less optimal value for mock classifiers plagued by anticipated systematic errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data\n",
    "====\n",
    "\n",
    "* mock classifier systematics\n",
    "* real classification results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method\n",
    "======\n",
    "\n",
    "* Brier score\n",
    "* Log-loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "=======\n",
    "\n",
    "*one plot per set of \"true\" classes: classifiers on x axis, metrics on y axes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions\n",
    "===========\n",
    "\n",
    "Write about your conclusions here. You have drawn some, right?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "no really, Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
