{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![](./header.png) -->\n",
    "<img src=\"./header.png\",width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection of a performance metric for PLAsTiCC\n",
    "\n",
    "*Alex Malz (NYU)*, *Tarek Alam (UCL)*, *Anita Bahmanyar (U. Toronto)*, *Rahul Biswas (U. Stockholm)*, *Renee Hlozek (U. Toronto)*, *Rafael Martinez-Galarza (Harvard)*, *Gautham Narayan (STScI)*\n",
    "\n",
    "We describe and illustrate the process by which a global performance metric was chosen for Photometric LSST Astronomical Time-series Classification Challenge (PLAsTiCC), a Kaggle competition aiming to identify promising transient and variable classifiers for LSST by involving the broader community outside astronomy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "============\n",
    "\n",
    "The metric of this note is for the first version of the Kaggle competition, though there are future plans for an early classification challenge and identification of class-specific metrics for different science goals.\n",
    "\n",
    "* The metric must return a single scalar value.\n",
    "* The metric must be well-defined for non-binary classes.\n",
    "* The metric must balance diverse science use cases in the presence of heavily nonuniform class prevalence.\n",
    "* The metric must respect the information content of probabilistic classifications.\n",
    "* The metric must be able to evaluate deterministic classifications.\n",
    "* The metric must be interpretable, meaning it gives a more optimal value for \"good\" mock classifiers and a less optimal value for mock classifiers plagued by anticipated systematic errors; in other words, it must pass basic tests of intuition.\n",
    "* The metric must be reliable, giving consistent results for different instantiations of the same test case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data\n",
    "====\n",
    "\n",
    "## Mock classifier systematics\n",
    "\n",
    "* idealized: highly accurate on all classes\n",
    "* guessing: random classifications across all classes\n",
    "* tunnel vision: classifies one class well and others randomly\n",
    "* cruise control: classifies all objects as a single class\n",
    "* subsumed: consistently misclassifies one class as one other class\n",
    "\n",
    "*show confusion matrices*\n",
    "\n",
    "## Real classification results\n",
    "\n",
    "* SNPhotCC \\[from Michelle?\\]\n",
    "* \\[Ashish's data?\\]\n",
    "* \\[Renee's data?\\]\n",
    "\n",
    "*show confusion matrices*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods (Metrics)\n",
    "======\n",
    "\n",
    "* Brier score\n",
    "* Log-loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "=======\n",
    "\n",
    "*one plot per set of \"true\" classes: classifiers on x axis, metrics on y axes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions\n",
    "===========\n",
    "\n",
    "Write about your conclusions here. You have drawn some, right?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "no really, Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
