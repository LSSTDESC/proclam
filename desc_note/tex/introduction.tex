\section{Introduction}
\label{sec:intro}

\aim{Fix citation format.}

Bright cosmological objects like Type Ia supernova are probes of cosmological distance (and hence probe the expansion of the universe). Core-collapse supernovae encode within their stunning demise the evolution properties of massive stars. Bright astrophysical transients like RR Lyrae give insight into the structure and evolution of stars. Active galactic nuclei probe the evolution of large massive galaxies. These are but some of the physical principles that are testable with the many different kinds of transients that will be delivered with the Large Synoptic Survey Telescope (LSST). With its rapid scan strategy, exquisite depth and many filters, LSST will deliver orders of magnitude more supernovae than are currently known, and will allow observers to find these obtjects at a range or redshifts (and hence distances) in the universe, allowing us to learn about how they change with cosmological time.

However, in order to make full use of the data samples at hand (depending on your current scientific case of interest), it is important to be able to classify different objects into classes, according to their photometric properties. The volume of discovery of LSST will make spectroscpic confirmation of the different types of objects impossible: any classifications of data into types will be based on the photometric (light curve) data of a given object.

The challenges of classification have been central to the transient community for many years (cite SNPhotCC, others), however previous challenges were restricted to either only a handful of different types of objects (eg. SNPhotCC), or have been tailored to a specific science case.

With the PLAsTiCC data we aim to develop a more complete set of simulations for an LSST-like survey, which will include some known objects, new models and also an `unknown' class of objects that have not been seen in data. The aim of this is to replicate the real world, where objects and new classes are found serendipitously in a given survey.

%\aim{Write background on \plasticc, Kaggle, previous classification challenges.}

Previous classification challenges (Kessler+10a, Kesser+10b) and efforts to develop supernova classifiers (Narayan+18) have focused on deterministic class assignments, but probabilistic classifications are desirable in the era of low signal-to-noise photometry. In order for the metric to be useful in such a heterogenous challenge, we require that the metric must return a single, scalar value, while being well-defined for non-binary classes.
In addition, the metric should balance diverse science use cases in the presence of heavily non-uniform classes. This is key given that the rates of astornomical transients of different types varies greatly: any classifier that requires a balance of types will under perform in the \plasticc (and other) competitions.

We impose the restriction that the metric must respect the information content of the probabilistic classifiers. Should a determininstic metric (i.e. a ``1'' or a ``0'' metric), that deterministic metric must be readily convertible into a probabilistic classification - and should preserve the relationships between classes accordingly. Similarly, any probabilistic metric much be easily transferred to a deterministic one (given, e.g. given a threshold on the most likely classficiation choice).

The metric must be interpretable, meaning it gives a more optimal value for ``good'' mock classif\
iers and a less optimal value for mock classifiers plagued by anticipated systematic errors; in other words, it must pass basic tests of intuition.

And finally, the metric must be reliable, giving consistent results for different instantiations of the same test case. While it is clear that different procedures will happen simultansously, the metric should be stable to these changes, and be able to rank different scenarious given any particular set of rules imposed upon the metric.

%\begin{itemize}
%\item    The metric must return a single scalar value.
%\item    The metric must be well-defined for non-binary classes.
%\item    The metric must balance diverse science use cases in the presence of heavily nonuniform class prevalence.
%\item    The metric must respect the information content of probabilistic classifications.
%\item    The metric must be able to evaluate deterministic classifications.
%\item    The metric must be interpretable, meaning it gives a more optimal value for "good" mock classifiers and a less optimal value for mock classifiers plagued by anticipated systematic errors; in other words, it must pass basic tests of intuition.
%\item    The metric must be reliable, giving consistent results for different instantiations of the same test case.
%\end{itemize}


In the context of astronomy, concerns about the choice of metric for probabilistic classifications have been investigated only to a limited degree thus far (Kim\&Brunner17, Florios+18, Bethapudi\&Desai18).
\aim{Summarize conclusions of these papers.}

The Probabilistic Classification Metric (ProClaM) code used in this exploration of performance metrics is publicly available on GitHub.\footnote{\url{https://github.com/aimalz/proclam}}
