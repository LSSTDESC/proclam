{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing classification probabilities\n",
    "\n",
    "_Alex Malz (GCCL@RUB)_\n",
    "\n",
    "Note: A lot of the cells here are very slow to run but only need to be run once, ever.\n",
    "The notebook will not run end-to-end unless you uncomment them and run them once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "import scipy.stats as sps\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "# print(mpl.rcParams.items)\n",
    "mpl.use('PS')\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "mpl.rcParams['mathtext.rm'] = 'serif'\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams[\"font.family\"] = \"serif\"\n",
    "mpl.rcParams[\"mathtext.fontset\"] = \"dejavuserif\"\n",
    "mpl.rcParams['font.serif'] = 'DejaVu Serif'\n",
    "# mpl.rcParams['text.usetex'] = False\n",
    "# mpl.rcParams['mathtext.rm'] = 'serif'\n",
    "# mpl.rcParams['font.weight'] = 'light'\n",
    "# mpl.rcParams['font.family'] = 'serif'\n",
    "# mpl.rcParams['font.serif'] = ['Times New Roman']\n",
    "# # mpl.rcParams['font.family'] = ['Times New Roman']\n",
    "mpl.rcParams['axes.titlesize'] = 20\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['savefig.dpi'] = 250\n",
    "mpl.rcParams['figure.dpi'] = 250\n",
    "mpl.rcParams['savefig.format'] = 'pdf'\n",
    "mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# print(mpl.rcParams.items)\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import pylab\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = mpl.colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "cmap = plt.get_cmap('hot_r')\n",
    "fave_cmap = truncate_colormap(cmap, 0.35, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proclam\n",
    "from proclam import *\n",
    "\n",
    "epsilon = 1.e-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truth table\n",
    "\n",
    "The true labels subdivide class 99 but the predicted labels don't (which breaks some `proclam.metrcs.util` functions, among other things).\n",
    "Warning, this fix is slow, so only run the cell below once and then read it in from a file next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use me if you've never run the notebook before.\n",
    "# truth = pd.read_csv('plasticc_test_metadata.csv')\n",
    "# header = ['object_id', 'true_target']\n",
    "# for i in [991, 992, 993, 994]:\n",
    "#     truth.loc[truth['true_target'] == i, 'true_target'] = 99\n",
    "# truth.to_csv('truth.csv', columns=header, index=False)\n",
    "\n",
    "## Use me if you've run the notebook before.\n",
    "truth = pd.read_csv('truth.csv', index_col='object_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_class_ids, true_class_counts = np.unique(truth['true_target'], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: replace the class numbers with informative names, and give them a logical ordering (SN together, etc.).\n",
    "This should also fix the problem with some old workarounds for class number mismatch that are still in the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell chops up the data into bite-sized pieces.\n",
    "It's slow but only needs to be done once.\n",
    "\n",
    "TODO: Also do this for the other three classifiers that made it into the paper, and use directories FFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run me only if you've never run the notebook before.\n",
    "\n",
    "# submission = pd.read_csv('1_Kyle.csv', index_col='object_id')\n",
    "# for i in truth.true_target.unique():\n",
    "#     to_save = submission[truth['true_target'] == i]\n",
    "#     to_save.to_csv('1_Kyle_'+str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to further split up the data into small pieces and calculate the KDE of each, which is also slow, though only has to be done once.\n",
    "\n",
    "TODO: smarter way to choose the kernel bandwidth -- the default is huge to the point of not being useful.  \n",
    "Probably the easiest fix is to use `scipy.stats.gaussian_kde` rather than `sklearn.neighbors.kde.KernelDensity` (assuming it's pickleable), which lets you automatically use Scott's rule to choose the bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run me only if you've never run the notebook before, or if you changed the bandwidth.\n",
    "\n",
    "# # for cl_est in all_prob.columns:\n",
    "# #     to_plot = all_prob[cl_est].values\n",
    "# #     to_plot = to_plot[:, np.newaxis]\n",
    "# #     kernel = KernelDensity(bandwidth=0.1).fit(to_plot)\n",
    "# #     data = np.exp(kernel.score_samples(positions[:, np.newaxis]))\n",
    "# #     print(data)\n",
    "# #     print('completed KDE for predicted class '+str(cl_est))\n",
    "# #     np.savetxt('violin'+str(one_target)+'true'+str(cl_est)+'pred.txt', data)\n",
    "# for one_target in true_class_ids:\n",
    "#     all_prob = pd.read_csv('1_Kyle_'+str(one_target)+'.csv', index_col='object_id')\n",
    "#     n_true = len(all_prob)\n",
    "#     print('calculating KDE for true class '+str(one_target)+' with '+str(n_true)+' objects')\n",
    "# #     minitruth = [one_target] * len(all_prob)\n",
    "#     # true_ind = list(all_prob.columns.values).index('class_'+str(one_target))\n",
    "#     pred_class_inds = {i: int(i[6:]) for i in all_prob.columns.values}\n",
    "# #     M_classes = len(pred_class_inds)\n",
    "#     all_prob.rename(columns=pred_class_inds, inplace=True)\n",
    "#     for cl_est in all_prob.columns:\n",
    "#         to_plot = all_prob[cl_est].values\n",
    "#         to_plot = to_plot[:, np.newaxis]\n",
    "#         kernel = KernelDensity(bandwidth=bw).fit(to_plot)\n",
    "#         with open('kernel'+str(one_target)+'true'+str(cl_est)+'pred.pkl', 'wb') as fn:\n",
    "#             pickle.dump(kernel, fn)\n",
    "# #         with open('kernel'+str(one_target)+'true'+str(cl_est)+'pred.pkl', 'rb') as fn:\n",
    "# #             kernel = pickle.load('kernel'+str(one_target)+'true'+str(cl_est)+'pred.pkl')\n",
    "# #         data = kernel.score_samples(positions[:, np.newaxis])\n",
    "#         print('completed KDE for predicted class '+str(cl_est))\n",
    "# #         np.savetxt('violin'+str(one_target)+'true'+str(cl_est)+'pred.txt', data)\n",
    "# #     violins(one_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the KDEs at grid points, unfortunately also slow (though I'm not sure why).\n",
    "It has to be re-reun for each updated set of grid points but saves the output so the plot can be tweaked without running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 50\n",
    "positions = np.linspace(0., 1., nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run me only if you've never run the notebook before, or if you changed the probabilities at which to evaluate the KDEs.\n",
    "# for one_target in true_class_ids:\n",
    "#     all_prob = pd.read_csv('1_Kyle_'+str(one_target)+'.csv', index_col='object_id')\n",
    "#     n_true = len(all_prob)\n",
    "#     print('evaluating KDEs for true class '+str(one_target)+' with '+str(n_true)+' objects')\n",
    "# #     minitruth = [one_target] * len(all_prob)\n",
    "#     # true_ind = list(all_prob.columns.values).index('class_'+str(one_target))\n",
    "#     pred_class_inds = {i: int(i[6:]) for i in all_prob.columns.values}\n",
    "# #     M_classes = len(pred_class_inds)\n",
    "# #     all_prob.rename(columns=pred_class_inds, inplace=True)\n",
    "#     for cl_est in all_prob.columns:\n",
    "# #         to_plot = all_prob[cl_est].values\n",
    "# #         to_plot = to_plot[:, np.newaxis]\n",
    "# #         kernel = KernelDensity(bandwidth=0.05).fit(to_plot)\n",
    "# #         with open('kernel'+str(one_target)+'true'+str(cl_est)+'pred.pkl', 'wb') as fn:\n",
    "# #             pickle.dump(kernel, fn)\n",
    "#         with open('kernel'+str(one_target)+'true'+str(cl_est)+'pred.pkl', 'rb') as fn:\n",
    "#             kernel = pickle.load(fn)\n",
    "#         data = kernel.score_samples(positions[:, np.newaxis])\n",
    "#         print('evaluated KDE for predicted class '+str(cl_est))\n",
    "#         np.savetxt('violin'+str(one_target)+'true'+str(cl_est)+'pred.txt', data)\n",
    "# #     violins(one_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the probabilities\n",
    "\n",
    "Voila, snazzy violin plots!\n",
    "\n",
    "TODO: Include the number of true objects in the title.\n",
    "\n",
    "TODO: Include the number with max probability in each predicted class within each violin.\n",
    "\n",
    "TODO: Look into a better way to normalize them for plotting purposes so the area is preserved and they don't run into each other.\n",
    "\n",
    "TODO: Consider combining these into subplots of a multipanel plot, one panel per true class and multiple classifiers per panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def violins(one_target):\n",
    "    loc = 0\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.set_title('true class '+str(one_target))\n",
    "    for cl_est in all_prob.columns:\n",
    "        if cl_est == one_target:\n",
    "            highlight = 'r'\n",
    "        else:\n",
    "            highlight = 'k'\n",
    "        data = np.exp(np.genfromtxt('violin'+str(one_target)+'true'+str(cl_est)+'pred.txt'))\n",
    "        data = data / np.max(data)\n",
    "        ax.fill_betweenx(positions, 2.5*loc - data, 2.5*loc + data, alpha=0.75, color=highlight)\n",
    "        loc += 1\n",
    "    ax.set_xticks(2.5 * np.arange(M_classes))\n",
    "    ax.set_xticklabels(all_prob.columns)\n",
    "    ax.set_xlabel('predicted class')\n",
    "    ax.set_ylabel('probability')\n",
    "    fig.savefig('violin'+str(one_target)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for one_target in true_class_ids:\n",
    "    violins(one_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least for Kyle's submission, classes 6, 15, 16, 53, 64, 65, 88, look pretty darn good, like what we'd expect from the \"perfect\" classifier archetype; class 90 looks more like the \"almost perfect\" or \"noisy\" classifier archetypes.\n",
    "Classes 42 and 62 look like the \"mutually subsuming\" classifier archetype, relative to class 99; class 67 looks like a weaker form of the \"mutually subsuming\" classifier archetype relative to classes 62, 90, and 99, and class 95 is also like that, relative to only class 99.\n",
    "Meanwhile, class 99 looks like the \"mutually subsuming\" classifier archetype relative to classes 42 and 62.\n",
    "Class 52 looks like the \"uncertain\" classifier archetype, with respect to classes 42, 62, 67, 90, and 99.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "TODO: Make another violin plot for the diagonal entry of the confusion matrix, i.e. the thing that our metric actually probes.\n",
    "\n",
    "TODO: Consider making one plot per predicted class, which sort of conveys a probabilistic notion of false positives, whereas making one plot per true class sort of conveys a probabilistic notion of false negatives.\n",
    "This would require splitting up the data files quite differently.\n",
    "\n",
    "Besides all the \"TODO\" items, I also want to try classifying the probability vectors (per true class) to get an idea of the covariances, at least for the weirdos like 42, 52, 62, 67."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data is unavailable, run the following cell to make trivial mock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M_classes = 13\n",
    "# flat_factor = 1. / M_classes\n",
    "# class_ids = range(0, M_classes)\n",
    "\n",
    "# oom = 4\n",
    "# generator = proclam.simulators.LogUnbalanced()\n",
    "# N_objects = int(10 ** oom)\n",
    "# minitruth = generator.simulate(M_classes, N_objects, base=oom)\n",
    "\n",
    "# mask_tru = det_to_prob(minitruth).astype(int)\n",
    "\n",
    "# starter = 0.5 * np.ones((M_classes, M_classes)) + 1.5 * np.eye(M_classes)\n",
    "# starter = starter / np.sum(starter, axis=1)[:, np.newaxis]\n",
    "# cm = starter\n",
    "\n",
    "# # afflicted = np.random.choice(range(0, M_classes), size=10, replace=False)\n",
    "# cruise = [-1, -2]#[0, 1]#afflicted[2:4]\n",
    "# subsumed = [-3, -4, -6, -7]#[2, 3, 5, 6]#afflicted[4:8]\n",
    "# swapped = [3, 4]#[-4, -5]\n",
    "# tunnel = [-1, -8]#[0, 7]#afflicted[8:]\n",
    "# noisy_cls = [0, 1]#[-2, -1]#afflicted[:2]\n",
    "# uncertain = [2]#[-3]\n",
    "# afflicted = cruise + subsumed + tunnel + noisy_cls\n",
    "\n",
    "# systematic_types = list(reversed([\n",
    "#     'perfect',\n",
    "#     'almost perfect',\n",
    "#     'cruise control by 11',\n",
    "#     'cruise control by 10',\n",
    "#     'almost perfect',\n",
    "#     'subsumed by 10',\n",
    "#     'subsumed by 10',\n",
    "#     'tunnel vision',\n",
    "#     'mutually subsuming',\n",
    "#     'mutually subsuming',\n",
    "#     'uncertain',\n",
    "#     'noisy',\n",
    "#     'noisy'\n",
    "# ]))\n",
    "# plot_systematic_types = list(reversed(systematic_types))\n",
    "\n",
    "# almost = 0.5 * np.ones((M_classes, M_classes)) + 1.5 * np.eye(M_classes)\n",
    "# almost = almost / np.sum(almost, axis=1)[:, np.newaxis]\n",
    "# cm = almost\n",
    "# perfect = np.eye(M_classes) + 1.e-8\n",
    "# cm[tunnel] = perfect[tunnel]\n",
    "# noisy = 0.5 * np.ones((M_classes, M_classes)) + 0.5 * np.eye(M_classes)\n",
    "# noisy = noisy / np.sum(starter, axis=1)[:, np.newaxis]\n",
    "# cm[noisy_cls] = noisy[noisy_cls]\n",
    "# cm[subsumed[-3:]] = cm[cruise[-1]]\n",
    "# cm[subsumed[:-3]] = cm[cruise[-2]]\n",
    "# cm[uncertain] = 1./float(M_classes) * np.ones(M_classes)\n",
    "# cm[swapped[-2]][swapped[-1]] = cm[swapped[-1]][swapped[-1]]\n",
    "# cm[swapped[-1]][swapped[-2]] = cm[swapped[-2]][swapped[-2]]\n",
    "# cm[:, -8] = perfect[:, -8]\n",
    "\n",
    "# cm = cm / np.sum(cm, axis=1)[:, np.newaxis]\n",
    "\n",
    "# fig = plt.figure(figsize=(5,5))\n",
    "# grid = ImageGrid(fig, 111,          # as in plt.subplot(111)\n",
    "#                  nrows_ncols=(1,1),\n",
    "#                  axes_pad=0.05,\n",
    "#                  share_all=True,\n",
    "#                  )\n",
    "# fig.subplots_adjust(wspace=0.5)\n",
    "# ax = grid[0]\n",
    "# im = ax.imshow(cm, vmin=0., vmax=1., cmap=fave_cmap)\n",
    "# ax.set_xticks(range(M_classes))\n",
    "# ax.set_xticklabels(range(1, M_classes+1))\n",
    "# ax.set_yticks(range(M_classes))\n",
    "# ax.set_yticklabels(range(1, M_classes+1))\n",
    "# ax.set_ylabel('true class')\n",
    "# ax.set_xlabel('predicted class')\n",
    "# cbar_ax = fig.add_axes([0.1, 0.89, 0.8, 0.04])\n",
    "# cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', pad=0.05)\n",
    "# cbar_ax.xaxis.set_ticks_position(\"top\")\n",
    "# ax.cax.toggle_label(True)\n",
    "# axp = ax.twinx()\n",
    "# axp.set_ylim(-0.5, M_classes-0.5)\n",
    "# axp.set_yticks(range(0, M_classes))\n",
    "# axp.set_yticklabels(plot_systematic_types)\n",
    "# axp.set_ylabel('systematic effect', rotation=270, labelpad=20)\n",
    "# ax.set_title('realistically complex \\n conditional probability matrix', pad=50)\n",
    "# # plt.savefig('fig/combined.png')\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "# # delfact = -1\n",
    "# # minidelta = 10**delfact\n",
    "# # altdelfact = delfact * 2\n",
    "# # altminidelta = 10**altdelfact\n",
    "\n",
    "# classifier = FromCMDM()\n",
    "# # delta = altminidelta\n",
    "\n",
    "# temp_cm = cm\n",
    "# temp_prob = sanitize_predictions(classifier.classify(temp_cm, minitruth, delta=0.001, other=False))\n",
    "\n",
    "# dets = prob_to_det(temp_prob)\n",
    "# cm = det_to_cm(dets, minitruth)\n",
    "# norm_cm = cm.astype(float).T\n",
    "# norm_cm[norm_cm == 0] = epsilon\n",
    "\n",
    "# fig = plt.figure(figsize=(5,5))\n",
    "# grid = ImageGrid(fig, 111,          # as in plt.subplot(111)\n",
    "#                  nrows_ncols=(1,1),\n",
    "#                  axes_pad=0.05,\n",
    "#                  share_all=True,\n",
    "#                  )\n",
    "# fig.subplots_adjust(wspace=0.5)\n",
    "# ax = grid[0]\n",
    "# im = ax.imshow(norm_cm, vmin=0.01, vmax=len(temp_prob), cmap=fave_cmap, norm=LogNorm())\n",
    "# ax.set_xticks(range(M_classes))\n",
    "# ax.set_xticklabels(pred_class_inds)\n",
    "# ax.set_yticks(range(M_classes))\n",
    "# ax.set_yticklabels(pred_class_inds)\n",
    "# ax.set_ylabel('true class')\n",
    "# ax.set_xlabel('predicted class')\n",
    "# cbar_ax = fig.add_axes([0.1, 0.89, 0.8, 0.04])\n",
    "# cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', pad=0.05)\n",
    "# cbar_ax.xaxis.set_ticks_position(\"top\")\n",
    "# ax.cax.toggle_label(True)\n",
    "# # axp = ax.twinx()\n",
    "# # axp.set_ylim(-0.5, M_classes-0.5)\n",
    "# # axp.set_yticks(range(0, M_classes))\n",
    "# # axp.set_yticklabels(plot_systematic_types)\n",
    "# # axp.set_ylabel('systematic effect', rotation=270, labelpad=20)\n",
    "# ax.set_title('confusion matrix for true '+str(one_target), pad=50)\n",
    "# # plt.savefig('fig/combined.png')\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly Seaborn can't handle multiple datasets on one set of axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.violinplot(probs.loc['true class' == 4].iloc[:])#data=per_class[\"true class\" == 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One target at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_target = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prob = pd.read_csv('1_Kyle_'+str(one_target)+'.csv', index_col='object_id')\n",
    "minitruth = [one_target] * len(all_prob)\n",
    "# true_ind = list(all_prob.columns.values).index('class_'+str(one_target))\n",
    "pred_class_inds = {i: int(i[6:]) for i in all_prob.columns.values}\n",
    "M_classes = len(pred_class_inds)\n",
    "all_prob.rename(columns=pred_class_inds, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stacked histogram really doesn't cut it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('probability vectors for true '+str(one_target))\n",
    "probbins = np.linspace(-2., 0., 20)\n",
    "plt.hist([all_prob[i] for i in all_prob.columns], bins=10.**probbins, density=True, stacked=True, \n",
    "         label=all_prob.columns, color=[fave_cmap(j/M_classes) for j in range(M_classes)])\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = all_prob.copy()\n",
    "# print((np.min(probs), np.max(probs)))\n",
    "# probs['true class'] = minitruth\n",
    "# # probs = pd.melt(probs, value_vars=[str(i) for i in range(M_classes)], id_vars='predicted class')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proclam (Python 3)",
   "language": "python",
   "name": "proclam_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
