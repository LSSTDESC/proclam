{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disagreement metrics\n",
    "\n",
    "_Alex Malz (GCCL@RUB)_ and {add your names here!}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# mpl.use('PS')\n",
    "# mpl.rcParams['text.usetex'] = False\n",
    "# mpl.rcParams['mathtext.rm'] = 'serif'\n",
    "# mpl.rcParams['font.family'] = 'serif'\n",
    "# mpl.rcParams[\"font.family\"] = \"serif\"\n",
    "# mpl.rcParams[\"mathtext.fontset\"] = \"dejavuserif\"\n",
    "# mpl.rcParams['font.serif'] = 'DejaVu Serif'\n",
    "# mpl.rcParams['axes.titlesize'] = 20\n",
    "# mpl.rcParams['axes.labelsize'] = 16\n",
    "# mpl.rcParams['xtick.labelsize'] = 12\n",
    "# mpl.rcParams['ytick.labelsize'] = 12\n",
    "# mpl.rcParams['savefig.dpi'] = 250\n",
    "# mpl.rcParams['figure.dpi'] = 250\n",
    "# mpl.rcParams['savefig.format'] = 'pdf'\n",
    "# mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from matplotlib.colors import LogNorm\n",
    "\n",
    "# import pylab\n",
    "# from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "# from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {90: 'SNIa',\n",
    "              67: 'SNIa-91bg',\n",
    "              52: 'SNIax',\n",
    "              42: 'SNII',\n",
    "              62: 'SNIbc',\n",
    "              95: 'SLSN-I',\n",
    "              15: 'TDE',\n",
    "              64: 'KN',\n",
    "              88: 'AGN',\n",
    "              92: 'RRL',\n",
    "              65: 'M-dwarf',\n",
    "              16: 'EB',\n",
    "              53: 'Mira',\n",
    "              6: r'$\\mu$Lens-Single'}\n",
    "\n",
    "true_labels = label_dict.copy()\n",
    "true_labels[991] = r'$\\mu$Lens-Binary'\n",
    "true_labels[992] = 'ILOT'\n",
    "true_labels[993] = 'CaRT'\n",
    "true_labels[994] = 'PISN'\n",
    "true_labels[995] = r'$mu$Lens-String'\n",
    "\n",
    "sub_labels = label_dict.copy()\n",
    "sub_labels[99] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contestants = ['1_Kyle', '2_MikeSilogram', '3_MajorTom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 50\n",
    "positions = np.linspace(0., 1., nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for one_target in label_dict.keys():\n",
    "    for cl_est in sub_labels.keys():\n",
    "        for contestant in contestants:\n",
    "            thepath = os.path.join('submissions/'+contestant, 'violin'+str(one_target)+'true'+str(cl_est)+'pred.txt')\n",
    "            data = np.exp(np.genfromtxt(thepath))\n",
    "            print(\"I just read in \"+contestant+\"'s violin curve of true \"+label_dict[one_target]+\" assigned \"+sub_labels[cl_est])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar metrics of disparity between 1-D probability densities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kullback-Leibler divergence\n",
    "\n",
    "Of each classifier relative to a \"ground truth\" of `'1_Kyle'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE\n",
    "\n",
    "Between classifier pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wasserstein distance\n",
    "\n",
    "Between classifier pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing metrics\n",
    "\n",
    "Plot the per-true-class, per-assigned-class, per-classifier metrics as a per-classifier $N_{class} \\times N_{class}$ matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing metrics\n",
    "\n",
    "Combine per-true-class, per-assigned-class, per-classifier-pair metrics into one scalar value per pair of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLAsTiCC (Python 3)",
   "language": "python",
   "name": "plasticc_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
