
@article{kessler_supernova_2010,
	title = {Supernova {Photometric} {Classification} {Challenge}},
	url = {http://arxiv.org/abs/1001.5210},
	abstract = {We have publicly released a blinded mix of simulated SNe, with types (Ia, Ib, Ic, II) selected in proportion to their expected rate. The simulation is realized in the griz filters of the Dark Energy Survey (DES) with realistic observing conditions (sky noise, point spread function and atmospheric transparency) based on years of recorded conditions at the DES site. Simulations of non-Ia type SNe are based on spectroscopically confirmed light curves that include unpublished non-Ia samples donated from the Carnegie Supernova Project (CSP), the Supernova Legacy Survey (SNLS), and the Sloan Digital Sky Survey-II (SDSS-II). We challenge scientists to run their classification algorithms and report a type for each SN. A spectroscopically confirmed subset is provided for training. The goals of this challenge are to (1) learn the relative strengths and weaknesses of the different classification algorithms, (2) use the results to improve classification algorithms, and (3) understand what spectroscopically confirmed sub-sets are needed to properly train these algorithms. The challenge is available at www.hep.anl.gov/SNchallenge, and the due date for classifications is May 1, 2010.},
	urldate = {2018-05-01},
	journal = {arXiv:1001.5210 [astro-ph]},
	author = {Kessler, Richard and Conley, Alex and Jha, Saurabh and Kuhlmann, Stephen},
	month = jan,
	year = {2010},
	note = {arXiv: 1001.5210},
}

@article{kessler_results_2010,
	title = {Results from the {Supernova} {Photometric} {Classification} {Challenge}},
	volume = {122},
	url = {http://iopscience.iop.org/article/10.1086/657607/meta},
	doi = {10.1086/657607},
	language = {en},
	number = {898},
	urldate = {2018-05-01},
	journal = {PASP},
	author = {Kessler, Richard and Bassett, Bruce and Belov, Pavel and Bhatnagar, Vasudha and Campbell, Heather and Conley, Alex and Frieman, Joshua A. and Glazov, Alexandre and Gonz{\'a}lez-Gait{\'a}n, Santiago and Hlozek, Ren{\'e}e and Jha, Saurabh and Kuhlmann, Stephen and Kunz, Martin and Lampeitl, Hubert and Mahabal, Ashish and Newling, James and Nichol, Robert C. and Parkinson, David and Philip, Ninan Sajeeth and Poznanski, Dovi and Richards, Joseph W. and Rodney, Steven A. and Sako, Masao and Schneider, Donald P. and Smith, Mathew and Stritzinger, Maximilian and Varughese, Melvin},
	month = nov,
	year = {2010},
	pages = {1415},
}

@article{narayan_machine_2018,
	title = {Machine {Learning}-based {Brokers} for {Real}-time {Classification} of the {LSST} {Alert} {Stream}},
	url = {http://arxiv.org/abs/1801.07323},
	abstract = {The unprecedented volume and rate of transient events that will be discovered by the Large Synoptic Survey Telescope (LSST) demands that the astronomical community update its followup paradigm. Alert-brokers -- automated software system to sift through, characterize, annotate and prioritize events for followup -- will be critical tools for managing alert streams in the LSST era. The Arizona-NOAO Temporal Analysis and Response to Events System (ANTARES) is one such broker. In this work, we develop a machine learning pipeline to characterize and classify variable and transient sources only using the available multiband optical photometry. We describe three illustrative stages of the pipeline, serving the three goals of early, intermediate and retrospective classification of alerts. The first takes the form of variable vs transient categorization, the second, a multi-class typing of the combined variable and transient dataset, and the third, a purity-driven subtyping of a transient class. While several similar algorithms have proven themselves in simulations, we validate their performance on real observations for the first time. We quantitatively evaluate our pipeline on sparse, unevenly sampled, heteroskedastic data from various existing observational campaigns, and demonstrate very competitive classification performance. We describe our progress towards adapting the pipeline developed in this work into a real-time broker working on live alert streams from time-domain surveys.},
	urldate = {2018-05-01},
	journal = {arXiv:1801.07323 [astro-ph]},
	author = {Narayan, Gautham and Zaidi, Tayeb and Soraisam, Monika D. and Wang, Zhe and Lochner, Michelle and Matheson, Thomas and Saha, Abhijit and Yang, Shuo and Zhao, Zhenge and Kececioglu, John and Scheidegger, Carlos and Snodgrass, Richard T. and Axelrod, Tim and Jenness, Tim and Maier, Robert S. and Ridgway, Stephen T. and Seaman, Robert L. and Evans, Eric Michael and Singh, Navdeep and Taylor, Clark and Toeniskoetter, Jackson and Welch, Eric and Zhu, Songzhe},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.07323},
}

@article{roberts_zbeams:_2017,
	title = {{zBEAMS}: a unified solution for supernova cosmology with redshift uncertainties},
	volume = {2017},
	shorttitle = {{zBEAMS}},
	url = {http://stacks.iop.org/1475-7516/2017/i=10/a=036},
	doi = {10.1088/1475-7516/2017/10/036},
	abstract = {Supernova cosmology without spectra will be an important component of future surveys such as LSST. This lack of supernova spectra results in uncertainty in the redshifts which, if ignored, leads to significantly biased estimates of cosmological parameters. Here we present a hierarchical Bayesian formalism{\textemdash} zBEAMS{\textemdash}that addresses this problem by marginalising over the unknown or uncertain supernova redshifts to produce unbiased cosmological estimates that are competitive with supernova data with spectroscopically confirmed redshifts. zBEAMS provides a unified treatment of both photometric redshifts and host galaxy misidentification (occurring due to chance galaxy alignments or faint hosts), effectively correcting the inevitable contamination in the Hubble diagram. Like its predecessor BEAMS, our formalism also takes care of non-Ia supernova contamination by marginalising over the unknown supernova type. We illustrate this technique with simulations of supernovae with photometric redshifts and host galaxy misidentification. A novel feature of the photometric redshift case is the important role played by the redshift distribution of the supernovae.},
	language = {en},
	number = {10},
	urldate = {2018-05-01},
	journal = {J. Cosmol. Astropart. Phys.},
	author = {Roberts, Ethan and Lochner, Michelle and Fonseca, Jos{\'e} and Bassett, Bruce A. and Lablanche, Pierre-Yves and Agarwal, Shankar},
	year = {2017},
	pages = {036},
}

@article{lochner_photometric_2016,
	title = {Photometric {Supernova} {Classification} with {Machine} {Learning}},
	volume = {225},
	url = {http://stacks.iop.org/0067-0049/225/i=2/a=31},
	doi = {10.3847/0067-0049/225/2/31},
	abstract = {Automated photometric supernova classification has become an active area of research in recent years in light of current and upcoming imaging surveys such as the Dark Energy Survey (DES) and the Large Synoptic Survey Telescope, given that spectroscopic confirmation of type for all supernovae discovered will be impossible. Here, we develop a multi-faceted classification pipeline, combining existing and new approaches. Our pipeline consists of two stages: extracting descriptive features from the light curves and classification using a machine learning algorithm. Our feature extraction methods vary from model-dependent techniques, namely SALT2 fits, to more independent techniques that fit parametric models to curves, to a completely model-independent wavelet approach. We cover a range of representative machine learning algorithms, including naive Bayes, k -nearest neighbors, support vector machines, artificial neural networks, and boosted decision trees (BDTs). We test the pipeline on simulated multi-band DES light curves from the Supernova Photometric Classification Challenge. Using the commonly used area under the curve (AUC) of the Receiver Operating Characteristic as a metric, we find that the SALT2 fits and the wavelet approach, with the BDTs algorithm, each achieve an AUC of 0.98, where 1 represents perfect classification. We find that a representative training set is essential for good classification, whatever the feature set or algorithm, with implications for spectroscopic follow-up. Importantly, we find that by using either the SALT2 or the wavelet feature sets with a BDT algorithm, accurate classification is possible purely from light curve data, without the need for any redshift information.},
	language = {en},
	number = {2},
	urldate = {2018-05-01},
	journal = {ApJS},
	author = {Lochner, Michelle and McEwen, Jason D. and Peiris, Hiranya V. and Lahav, Ofer and Winter, Max K.},
	year = {2016},
	pages = {31},
}