
@article{pedregosa_scikit-learn:_2011,
	title = {Scikit-learn: {Machine} learning in {Python}},
	volume = {12},
	shorttitle = {Scikit-learn},
	url = {http://www.jmlr.org/papers/v12/pedregosa11a.html},
	number = {Oct},
	urldate = {2017-08-30},
	journal = {J Machine Learning Res},
	author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and {others}},
	year = {2011},
	pages = {2825--2830},
	file = {pedregosa11a.pdf:/home/aimalz/Documents/References/storage/FIJ6XGDI/pedregosa11a.pdf:application/pdf}
}

@book{oliphant_guide_2006,
	address = {USA},
	title = {A guide to {NumPy}},
	url = {http://www.numpy.org/},
	publisher = {Trelgol Publishing},
	author = {Oliphant, Travis E.},
	year = {2006}
}

@misc{jones_scipy:_2001,
	title = {{SciPy}: {Open} {Source} {Scientific} {Tools} for {Python}},
	url = {https://www.scipy.org/},
	author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu},
	year = {2001}
}

@article{hunter_matplotlib:_2007,
	title = {Matplotlib: {A} 2D {Graphics} {Environment}},
	volume = {9},
	issn = {1521-9615},
	shorttitle = {Matplotlib},
	doi = {10.1109/MCSE.2007.55},
	abstract = {Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems},
	number = {3},
	journal = {Computing in Science Engineering},
	author = {Hunter, J. D.},
	month = may,
	year = {2007},
	keywords = {2D graphics package, application development, computer graphics, Computer languages, Equations, Graphical user interfaces, Graphics, Image generation, interactive scripting, Interpolation, mathematics computing, Matplotlib, object-oriented programming, operating system, Operating systems, Packaging, Programming profession, publication-quality image generation, Python, scientific programming, scripting languages, software packages, user interface, User interfaces},
	pages = {90--95},
	file = {IEEE Xplore Abstract Record:/home/aimalz/Documents/References/storage/Q3Q8X7A6/4160265.html:text/html;IEEE Xplore Full Text PDF:/home/aimalz/Documents/References/storage/96S8KF8W/Hunter - 2007 - Matplotlib A 2D Graphics Environment.pdf:application/pdf}
}

@inproceedings{kluyver_jupyter_2016,
	title = {Jupyter {Notebooks}-a publishing format for reproducible computational workflows.},
	booktitle = {{ELPUB}},
	author = {Kluyver, Thomas and Ragan-Kelley, Benjamin and P{\'e}rez, Fernando and Granger, Brian E. and Bussonnier, Matthias and Frederic, Jonathan and Kelley, Kyle and Hamrick, Jessica B. and Grout, Jason and Corlay, Sylvain},
	year = {2016},
	pages = {87--90},
	file = {STAL9781614996491-0087.pdf:/home/aimalz/Documents/References/storage/9HSAUBZG/STAL9781614996491-0087.pdf:application/pdf}
}

@article{walt_numpy_2011,
	title = {The {NumPy} {Array}: {A} {Structure} for {Efficient} {Numerical} {Computation}},
	volume = {13},
	issn = {1521-9615},
	shorttitle = {The {NumPy} {Array}},
	url = {doi.ieeecomputersociety.org/10.1109/MCSE.2011.37},
	abstract = {{\textless}p{\textgreater}In the Python world, NumPy arrays are the standard representation for numerical data and enable efficient implementation of numerical computations in a high-level language. As this effort shows, NumPy performance can be improved through three techniques: vectorizing calculations, avoiding copying data in memory, and minimizing operation counts.{\textless}/p{\textgreater}},
	number = {2},
	urldate = {2018-04-06},
	journal = {Computing in Science \& Engineering},
	author = {Walt, S. v and Colbert, S. C. and Varoquaux, G.},
	year = {2011},
	doi = {10.1109/MCSE.2011.37},
	keywords = {Python, scientific programming, numerical computations, NumPy, programming libraries},
	pages = {22--30},
	file = {Snapshot:/home/aimalz/Documents/References/storage/69Z3K5NW/mcs2011020022-abs.html:text/html}
}

@article{kessler_supernova_2010,
	title = {Supernova {Photometric} {Classification} {Challenge}},
	url = {http://arxiv.org/abs/1001.5210},
	abstract = {We have publicly released a blinded mix of simulated SNe, with types (Ia, Ib, Ic, II) selected in proportion to their expected rate. The simulation is realized in the griz filters of the Dark Energy Survey (DES) with realistic observing conditions (sky noise, point spread function and atmospheric transparency) based on years of recorded conditions at the DES site. Simulations of non-Ia type SNe are based on spectroscopically confirmed light curves that include unpublished non-Ia samples donated from the Carnegie Supernova Project (CSP), the Supernova Legacy Survey (SNLS), and the Sloan Digital Sky Survey-II (SDSS-II). We challenge scientists to run their classification algorithms and report a type for each SN. A spectroscopically confirmed subset is provided for training. The goals of this challenge are to (1) learn the relative strengths and weaknesses of the different classification algorithms, (2) use the results to improve classification algorithms, and (3) understand what spectroscopically confirmed sub-sets are needed to properly train these algorithms. The challenge is available at www.hep.anl.gov/SNchallenge, and the due date for classifications is May 1, 2010.},
	urldate = {2018-05-01},
	journal = {arXiv:1001.5210 [astro-ph]},
	author = {Kessler, Richard and Conley, Alex and Jha, Saurabh and Kuhlmann, Stephen},
	month = jan,
	year = {2010},
	note = {arXiv: 1001.5210},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
	file = {arXiv\:1001.5210 PDF:/home/aimalz/Documents/References/storage/NV4GQ7JQ/Kessler et al. - 2010 - Supernova Photometric Classification Challenge.pdf:application/pdf;arXiv\:1001.5210 PDF:/home/aimalz/Documents/References/storage/3H2DYRZE/Kessler et al. - 2010 - Supernova Photometric Classification Challenge.pdf:application/pdf;arXiv.org Snapshot:/home/aimalz/Documents/References/storage/9SFKRMMH/1001.html:text/html;arXiv.org Snapshot:/home/aimalz/Documents/References/storage/NVYUBSZJ/1001.html:text/html}
}

@article{kessler_results_2010,
	title = {Results from the {Supernova} {Photometric} {Classification} {Challenge}},
	volume = {122},
	issn = {1538-3873},
	url = {http://iopscience.iop.org/article/10.1086/657607/meta},
	doi = {10.1086/657607},
	language = {en},
	number = {898},
	urldate = {2018-05-01},
	journal = {PASP},
	author = {Kessler, Richard and Bassett, Bruce and Belov, Pavel and Bhatnagar, Vasudha and Campbell, Heather and Conley, Alex and Frieman, Joshua A. and Glazov, Alexandre and Gonz{\'a}lez-Gait{\'a}n, Santiago and Hlozek, Ren{\'e}e and Jha, Saurabh and Kuhlmann, Stephen and Kunz, Martin and Lampeitl, Hubert and Mahabal, Ashish and Newling, James and Nichol, Robert C. and Parkinson, David and Philip, Ninan Sajeeth and Poznanski, Dovi and Richards, Joseph W. and Rodney, Steven A. and Sako, Masao and Schneider, Donald P. and Smith, Mathew and Stritzinger, Maximilian and Varughese, Melvin},
	month = nov,
	year = {2010},
	pages = {1415},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/MBPIA5WS/Kessler et al. - 2010 - Results from the Supernova Photometric Classificat.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/KG8AALJX/657607.html:text/html}
}

@article{roberts_zbeams:_2017,
	title = {{zBEAMS}: a unified solution for supernova cosmology with redshift uncertainties},
	volume = {2017},
	issn = {1475-7516},
	shorttitle = {{zBEAMS}},
	url = {http://stacks.iop.org/1475-7516/2017/i=10/a=036},
	doi = {10.1088/1475-7516/2017/10/036},
	abstract = {Supernova cosmology without spectra will be an important component of future surveys such as LSST. This lack of supernova spectra results in uncertainty in the redshifts which, if ignored, leads to significantly biased estimates of cosmological parameters. Here we present a hierarchical Bayesian formalism{\textemdash} zBEAMS{\textemdash}that addresses this problem by marginalising over the unknown or uncertain supernova redshifts to produce unbiased cosmological estimates that are competitive with supernova data with spectroscopically confirmed redshifts. zBEAMS provides a unified treatment of both photometric redshifts and host galaxy misidentification (occurring due to chance galaxy alignments or faint hosts), effectively correcting the inevitable contamination in the Hubble diagram. Like its predecessor BEAMS, our formalism also takes care of non-Ia supernova contamination by marginalising over the unknown supernova type. We illustrate this technique with simulations of supernovae with photometric redshifts and host galaxy misidentification. A novel feature of the photometric redshift case is the important role played by the redshift distribution of the supernovae.},
	language = {en},
	number = {10},
	urldate = {2018-05-01},
	journal = {J. Cosmol. Astropart. Phys.},
	author = {Roberts, Ethan and Lochner, Michelle and Fonseca, Jos{\'e} and Bassett, Bruce A. and Lablanche, Pierre-Yves and Agarwal, Shankar},
	year = {2017},
	pages = {036},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/HS88HIGJ/Roberts et al. - 2017 - zBEAMS a unified solution for supernova cosmology.pdf:application/pdf}
}

@article{lochner_photometric_2016,
	title = {Photometric {Supernova} {Classification} with {Machine} {Learning}},
	volume = {225},
	issn = {0067-0049},
	url = {http://stacks.iop.org/0067-0049/225/i=2/a=31},
	doi = {10.3847/0067-0049/225/2/31},
	abstract = {Automated photometric supernova classification has become an active area of research in recent years in light of current and upcoming imaging surveys such as the Dark Energy Survey (DES) and the Large Synoptic Survey Telescope, given that spectroscopic confirmation of type for all supernovae discovered will be impossible. Here, we develop a multi-faceted classification pipeline, combining existing and new approaches. Our pipeline consists of two stages: extracting descriptive features from the light curves and classification using a machine learning algorithm. Our feature extraction methods vary from model-dependent techniques, namely SALT2 fits, to more independent techniques that fit parametric models to curves, to a completely model-independent wavelet approach. We cover a range of representative machine learning algorithms, including naive Bayes, k -nearest neighbors, support vector machines, artificial neural networks, and boosted decision trees (BDTs). We test the pipeline on simulated multi-band DES light curves from the Supernova Photometric Classification Challenge. Using the commonly used area under the curve (AUC) of the Receiver Operating Characteristic as a metric, we find that the SALT2 fits and the wavelet approach, with the BDTs algorithm, each achieve an AUC of 0.98, where 1 represents perfect classification. We find that a representative training set is essential for good classification, whatever the feature set or algorithm, with implications for spectroscopic follow-up. Importantly, we find that by using either the SALT2 or the wavelet feature sets with a BDT algorithm, accurate classification is possible purely from light curve data, without the need for any redshift information.},
	language = {en},
	number = {2},
	urldate = {2018-05-01},
	journal = {ApJS},
	author = {Lochner, Michelle and McEwen, Jason D. and Peiris, Hiranya V. and Lahav, Ofer and Winter, Max K.},
	year = {2016},
	pages = {31},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/6EPXMN4P/Lochner et al. - 2016 - Photometric Supernova Classification with Machine .pdf:application/pdf}
}

@article{narayan_machine_2018,
	title = {Machine {Learning}-based {Brokers} for {Real}-time {Classification} of the {LSST} {Alert} {Stream}},
	volume = {236},
	issn = {1538-4365},
	url = {http://arxiv.org/abs/1801.07323},
	doi = {10.3847/1538-4365/aab781},
	abstract = {The unprecedented volume and rate of transient events that will be discovered by the Large Synoptic Survey Telescope (LSST) demands that the astronomical community update its followup paradigm. Alert-brokers -- automated software system to sift through, characterize, annotate and prioritize events for followup -- will be critical tools for managing alert streams in the LSST era. The Arizona-NOAO Temporal Analysis and Response to Events System (ANTARES) is one such broker. In this work, we develop a machine learning pipeline to characterize and classify variable and transient sources only using the available multiband optical photometry. We describe three illustrative stages of the pipeline, serving the three goals of early, intermediate and retrospective classification of alerts. The first takes the form of variable vs transient categorization, the second, a multi-class typing of the combined variable and transient dataset, and the third, a purity-driven subtyping of a transient class. While several similar algorithms have proven themselves in simulations, we validate their performance on real observations for the first time. We quantitatively evaluate our pipeline on sparse, unevenly sampled, heteroskedastic data from various existing observational campaigns, and demonstrate very competitive classification performance. We describe our progress towards adapting the pipeline developed in this work into a real-time broker working on live alert streams from time-domain surveys.},
	number = {1},
	urldate = {2018-06-05},
	journal = {The Astrophysical Journal Supplement Series},
	author = {Narayan, Gautham and Zaidi, Tayeb and Soraisam, Monika D. and Wang, Zhe and Lochner, Michelle and Matheson, Thomas and Saha, Abhijit and Yang, Shuo and Zhao, Zhenge and Kececioglu, John and Scheidegger, Carlos and Snodgrass, Richard T. and Axelrod, Tim and Jenness, Tim and Maier, Robert S. and Ridgway, Stephen T. and Seaman, Robert L. and Evans, Eric Michael and Singh, Navdeep and Taylor, Clark and Toeniskoetter, Jackson and Welch, Eric and Zhu, Songzhe},
	month = may,
	year = {2018},
	note = {arXiv: 1801.07323},
	keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - High Energy Astrophysical Phenomena},
	pages = {9},
	file = {arXiv\:1801.07323 PDF:/home/aimalz/Documents/References/storage/4R9ZMGGN/Narayan et al. - 2018 - Machine Learning-based Brokers for Real-time Class.pdf:application/pdf;arXiv\:1801.07323 PDF:/home/aimalz/Documents/References/storage/YI7PZ2BW/Narayan et al. - 2018 - Machine Learning-based Brokers for Real-time Class.pdf:application/pdf;arXiv.org Snapshot:/home/aimalz/Documents/References/storage/BAUGHABV/1801.html:text/html;arXiv.org Snapshot:/home/aimalz/Documents/References/storage/TTR8X4NX/1801.html:text/html}
}

@article{crown_validation_2012,
	title = {Validation of the {NOAA} {Space} {Weather} {Prediction} {Center}'s solar flare forecasting look-up table and forecaster-issued probabilities},
	volume = {10},
	copyright = {This paper is not subject to U.S. copyright. Published in 2012 by the American Geophysical          Union},
	issn = {1542-7390},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2011SW000760},
	doi = {10.1029/2011SW000760},
	abstract = {This paper provides an assessment of the operational solar flare look-up table currently in use at the National Oceanic and Atmospheric Administration (NOAA) Space Weather Prediction Center (SWPC) during solar cycle 23 (May 1996 {\textendash} December 2008). To assess the value of human interaction, a validation of subjective flare probability forecasts was conducted and compared to the results obtained from the climatological look-up table used at SWPC. Probabilistic flare forecasts are evaluated using the Brier Skill Score, then discretized and entered into contingency tables from which a variety of verification measures are calculated. The ultimate goal of this report is to provide an operational baseline, whereby the scores and statistics from this paper can be used as the basis for future evaluation of models presented to the operational community.},
	language = {en},
	number = {6},
	urldate = {2018-07-09},
	journal = {Space Weather},
	author = {Crown, Misty D.},
	month = jun,
	year = {2012},
	keywords = {flares, forecasting},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/VWZTVEWZ/Crown - Validation of the NOAA Space Weather Prediction Ce.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/E5NGYV7U/2011SW000760.html:text/html}
}

@article{richards_construction_2012,
	title = {Construction of a {Calibrated} {Probabilistic} {Classification} {Catalog}: {Application} to 50k {Variable} {Sources} in the {All}-{Sky} {Automated} {Survey}},
	volume = {203},
	issn = {0067-0049},
	shorttitle = {Construction of a {Calibrated} {Probabilistic} {Classification} {Catalog}},
	url = {http://stacks.iop.org/0067-0049/203/i=2/a=32},
	doi = {10.1088/0067-0049/203/2/32},
	abstract = {With growing data volumes from synoptic surveys, astronomers necessarily must become more abstracted from the discovery and introspection processes. Given the scarcity of follow-up resources, there is a particularly sharp onus on the frameworks that replace these human roles to provide accurate and well-calibrated probabilistic classification catalogs. Such catalogs inform the subsequent follow-up, allowing consumers to optimize the selection of specific sources for further study and permitting rigorous treatment of classification purities and efficiencies for population studies. Here, we describe a process to produce a probabilistic classification catalog of variability with machine learning from a multi-epoch photometric survey. In addition to producing accurate classifications, we show how to estimate calibrated class probabilities and motivate the importance of probability calibration. We also introduce a methodology for feature-based anomaly detection, which allows discovery of objects in the survey that do not fit within the predefined class taxonomy. Finally, we apply these methods to sources observed by the All-Sky Automated Survey (ASAS), and release the Machine-learned ASAS Classification Catalog (MACC), a 28 class probabilistic classification catalog of 50,124 ASAS sources in the ASAS Catalog of Variable Stars. We estimate that MACC achieves a sub-20\% classification error rate and demonstrate that the class posterior probabilities are reasonably calibrated. MACC classifications compare favorably to the classifications of several previous domain-specific ASAS papers and to the ASAS Catalog of Variable Stars, which had classified only 24\% of those sources into one of 12 science classes.},
	language = {en},
	number = {2},
	urldate = {2018-07-09},
	journal = {ApJS},
	author = {Richards, Joseph W. and Starr, Dan L. and Miller, Adam A. and Bloom, Joshua S. and Butler, Nathaniel R. and {Henrik Brink} and Crellin-Quick, Arien},
	year = {2012},
	pages = {32},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/ETX7PM7G/Richards et al. - 2012 - Construction of a Calibrated Probabilistic Classif.pdf:application/pdf}
}

@article{mays_ensemble_2015,
	title = {Ensemble {Modeling} of {CMEs} {Using} the {WSA}{\textendash}{ENLIL}+{Cone} {Model}},
	volume = {290},
	issn = {0038-0938, 1573-093X},
	url = {https://link.springer.com/article/10.1007/s11207-015-0692-1},
	doi = {10.1007/s11207-015-0692-1},
	abstract = {Ensemble modeling of coronal mass ejections (CMEs) provides a probabilistic forecast of CME arrival time that includes an estimation of arrival-time uncertainty from the spread and distribution of predictions and forecast confidence in the likelihood of CME arrival. The real-time ensemble modeling of CME propagation uses the Wang{\textendash}Sheeley{\textendash}Arge (WSA){\textendash}ENLIL+Cone model installed at the Community Coordinated Modeling Center (CCMC) and executed in real-time at the CCMC/Space Weather Research Center. The current implementation of this ensemble-modeling method evaluates the sensitivity of WSA{\textendash}ENLIL+Cone model simulations of CME propagation to initial CME parameters. We discuss the results of real-time ensemble simulations for a total of 35 CME events that occurred between January 2013 {\textendash} July 2014. For the 17 events where the CME was predicted to arrive at Earth, the mean absolute arrival-time prediction error was 12.3 hours, which is comparable to the errors reported in other studies. For predictions of CME arrival at Earth, the correct-rejection rate is 62 \%, the false-alarm rate is 38 \%, the correct-alarm ratio is 77 \%, and the false-alarm ratio is 23 \%. The arrival time was within the range of the ensemble arrival predictions for 8 out of 17 events. The Brier Score for CME arrival-predictions is 0.15 (where a score of 0 on a range of 0 to 1 is a perfect forecast), which indicates that on average, the predicted probability, or likelihood, of CME arrival is fairly accurate. The reliability of ensemble CME-arrival predictions is heavily dependent on the initial distribution of CME input parameters (e.g. speed, direction, and width), particularly the median and spread. Preliminary analysis of the probabilistic forecasts suggests undervariability, indicating that these ensembles do not sample a wide-enough spread in CME input parameters. Prediction errors can also arise from ambient-model parameters, the accuracy of the solar-wind background derived from coronal maps, or other model limitations. Finally, predictions of the K P geomagnetic index differ from observed values by less than one for 11 out of 17 of the ensembles and K P prediction errors computed from the mean predicted K P show a mean absolute error of 1.3.},
	language = {en},
	number = {6},
	urldate = {2018-07-09},
	journal = {Sol Phys},
	author = {Mays, M. L. and Taktakishvili, A. and Pulkkinen, A. and MacNeice, P. J. and Rast{\"a}tter, L. and Odstrcil, D. and Jian, L. K. and Richardson, I. G. and LaSota, J. A. and Zheng, Y. and Kuznetsova, M. M.},
	month = jun,
	year = {2015},
	pages = {1775--1814},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/QEBIDI76/Mays et al. - 2015 - Ensemble Modeling of CMEs Using the WSA{\textendash}ENLIL+Cone.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/BZINT7LE/10.html:text/html}
}

@article{kim_hybrid_2015,
	title = {A hybrid ensemble learning approach to star{\textendash}galaxy classification},
	volume = {453},
	issn = {0035-8711},
	url = {https://academic.oup.com/mnras/article/453/1/507/1749701},
	doi = {10.1093/mnras/stv1608},
	abstract = {Abstract.  There exist a variety of star{\textendash}galaxy classification techniques, each with their own strengths and weaknesses. In this paper, we present a novel meta-},
	language = {en},
	number = {1},
	urldate = {2018-07-09},
	journal = {Mon Not R Astron Soc},
	author = {Kim, Edward J. and Brunner, Robert J. and Carrasco Kind, Matias},
	month = oct,
	year = {2015},
	pages = {507--521},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/JG8MNGD5/Kim et al. - 2015 - A hybrid ensemble learning approach to star{\textendash}galaxy.pdf:application/pdf}
}

@article{armstrong_k2_2016,
	title = {K2 variable catalogue {\textendash} {II}. {Machine} learning classification of variable stars and eclipsing binaries in {K}2 fields 0{\textendash}4},
	volume = {456},
	issn = {0035-8711},
	url = {https://academic.oup.com/mnras/article/456/2/2260/1071207},
	doi = {10.1093/mnras/stv2836},
	abstract = {Abstract.  We are entering an era of unprecedented quantities of data from current and planned survey telescopes. To maximize the potential of such surveys, aut},
	language = {en},
	number = {2},
	urldate = {2018-07-09},
	journal = {Mon Not R Astron Soc},
	author = {Armstrong, D. J. and Kirk, J. and Lam, K. W. F. and McCormac, J. and Osborn, H. P. and Spake, J. and Walker, S. and Brown, D. J. A. and Kristiansen, M. H. and Pollacco, D. and West, R. and Wheatley, P. J.},
	month = feb,
	year = {2016},
	pages = {2260--2272},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/75I3VKTA/Armstrong et al. - 2016 - K2 variable catalogue {\textendash} II. Machine learning class.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/G2XF6B6R/1071207.html:text/html}
}

@article{brier_verification_1950,
	title = {Verification of forecasts expressed in terms of probability},
	volume = {78},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281950%29078%3C0001%3AVOFEIT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2},
	abstract = {No Abstract Available.},
	number = {1},
	urldate = {2018-07-09},
	journal = {Mon. Wea. Rev.},
	author = {Brier, Glenn W.},
	month = jan,
	year = {1950},
	pages = {1--3},
	file = {mwr-078-01-0001.pdf:/home/aimalz/Documents/References/storage/AK89UIM9/mwr-078-01-0001.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/ZEKE9B9J/1520-0493(1950)0780001VOFEIT2.0.html:text/html}
}

@article{kim_stargalaxy_2017,
	title = {Star{\textendash}galaxy classification using deep convolutional neural networks},
	volume = {464},
	issn = {0035-8711},
	url = {https://academic.oup.com/mnras/article/464/4/4463/2417400},
	doi = {10.1093/mnras/stw2672},
	abstract = {Abstract.  Most existing star{\textendash}galaxy classifiers use the reduced summary information from catalogues, requiring careful feature extraction and selection. The la},
	language = {en},
	number = {4},
	urldate = {2018-07-09},
	journal = {Mon Not R Astron Soc},
	author = {Kim, Edward J. and Brunner, Robert J.},
	month = feb,
	year = {2017},
	pages = {4463--4475},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/J7SGAR9P/Kim and Brunner - 2017 - Star{\textendash}galaxy classification using deep convolutiona.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/L8XK2G5E/2417400.html:text/html}
}

@article{florios_forecasting_2018,
	title = {Forecasting {Solar} {Flares} {Using} {Magnetogram}-based {Predictors} and {Machine} {Learning}},
	volume = {293},
	issn = {0038-0938, 1573-093X},
	url = {https://link.springer.com/article/10.1007/s11207-018-1250-4},
	doi = {10.1007/s11207-018-1250-4},
	abstract = {We propose a forecasting approach for solar flares based on data from Solar Cycle 24, taken by the Helioseismic and Magnetic Imager (HMI) on board the Solar Dynamics Observatory (SDO) mission. In particular, we use the Space-weather HMI Active Region Patches (SHARP) product that facilitates cut-out magnetograms of solar active regions (AR) in the Sun in near-realtime (NRT), taken over a five-year interval (2012 {\textendash} 2016). Our approach utilizes a set of thirteen predictors, which are not included in the SHARP metadata, extracted from line-of-sight and vector photospheric magnetograms. We exploit several machine learning (ML) and conventional statistics techniques to predict flares of peak magnitude {\textgreater}M1{\textgreater}M1\{{\textgreater}\}{\textbackslash},{\textbackslash}mbox\{M1\} and {\textgreater}C1{\textgreater}C1\{{\textgreater}\}{\textbackslash},{\textbackslash}mbox\{C1\} within a 24 h forecast window. The ML methods used are multi-layer perceptrons (MLP), support vector machines (SVM), and random forests (RF). We conclude that random forests could be the prediction technique of choice for our sample, with the second-best method being multi-layer perceptrons, subject to an entropy objective function. A Monte Carlo simulation showed that the best-performing method gives accuracy ACC=0.93(0.00)ACC=0.93(0.00){\textbackslash}mathrm\{ACC\}=0.93(0.00), true skill statistic TSS=0.74(0.02)TSS=0.74(0.02){\textbackslash}mathrm\{TSS\}=0.74(0.02), and Heidke skill score HSS=0.49(0.01)HSS=0.49(0.01){\textbackslash}mathrm\{HSS\}=0.49(0.01) for {\textgreater}M1{\textgreater}M1\{{\textgreater}\}{\textbackslash},{\textbackslash}mbox\{M1\} flare prediction with probability threshold 15\% and ACC=0.84(0.00)ACC=0.84(0.00){\textbackslash}mathrm\{ACC\}=0.84(0.00), TSS=0.60(0.01)TSS=0.60(0.01){\textbackslash}mathrm\{TSS\}=0.60(0.01), and HSS=0.59(0.01)HSS=0.59(0.01){\textbackslash}mathrm\{HSS\}=0.59(0.01) for {\textgreater}C1{\textgreater}C1\{{\textgreater}\}{\textbackslash},{\textbackslash}mbox\{C1\} flare prediction with probability threshold 35\%.},
	language = {en},
	number = {2},
	urldate = {2018-07-09},
	journal = {Sol Phys},
	author = {Florios, Kostas and Kontogiannis, Ioannis and Park, Sung-Hong and Guerra, Jordan A. and Benvenuto, Federico and Bloomfield, D. Shaun and Georgoulis, Manolis K.},
	month = feb,
	year = {2018},
	pages = {28},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/L7WERD2P/Florios et al. - 2018 - Forecasting Solar Flares Using Magnetogram-based P.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/P22P9YMB/10.html:text/html}
}

@article{mccloskey_flare_2018,
	title = {Flare {Forecasting} {Using} the {Evolution} of {McIntosh} {Sunspot} {Classifications}},
	url = {http://arxiv.org/abs/1805.00919},
	abstract = {Most solar flares originate in sunspot groups, where magnetic field changes lead to energy build-up and release. However, few flare-forecasting methods use information of sunspot-group evolution, instead focusing on static point-in-time observations. Here, a new forecast method is presented based upon the 24-hr evolution in McIntosh classification of sunspot groups. Evolution-dependent \${\textbackslash}geqslant\$C1.0 and \${\textbackslash}geqslant\$M1.0 flaring rates are found from NOAA-numbered sunspot groups over December 1988 to June 1996 (Solar Cycle 22; SC22) before converting to probabilities assuming Poisson statistics. These flaring probabilities are used to generate operational forecasts for sunspot groups over July 1996 to December 2008 (SC23), with performance studied by verification metrics. Major findings are: i) considering Brier skill score (BSS) for \${\textbackslash}geqslant\$C1.0 flares, the evolution-dependent McIntosh-Poisson method (\${\textbackslash}text\{BSS\}\_\{{\textbackslash}text\{evolution\}\}=0.09\$) performs better than the static McIntosh-Poisson method (\${\textbackslash}text\{BSS\}\_\{{\textbackslash}text\{static\}\} = -0.09\$); ii) low BSS values arise partly from both methods over-forecasting SC23 flares from the SC22 rates, symptomatic of \${\textbackslash}geqslant\$C1.0 rates in SC23 being on average \${\textbackslash}approx\$80\% of those in SC22 (with \${\textbackslash}geqslant\$M1.0 being \${\textbackslash}approx\$50\%); iii) applying a bias-correction factor to reduce the SC22 rates used in forecasting SC23 flares yields modest improvement in skill relative to climatology for both methods (\${\textbackslash}mathrm\{BSS\}{\textasciicircum}\{{\textbackslash}mathrm\{corr\}\}\_\{{\textbackslash}mathrm\{static\}\} = 0.09\$ and \${\textbackslash}mathrm\{BSS\}{\textasciicircum}\{{\textbackslash}mathrm\{corr\}\}\_\{{\textbackslash}mathrm\{evolution\}\} = 0.20\$) and improved forecast reliability diagrams.},
	urldate = {2018-07-09},
	journal = {arXiv:1805.00919 [astro-ph]},
	author = {McCloskey, Aoife E. and Gallagher, Peter T. and Bloomfield, D. Shaun},
	month = may,
	year = {2018},
	note = {arXiv: 1805.00919},
	keywords = {Astrophysics - Solar and Stellar Astrophysics},
	file = {arXiv\:1805.00919 PDF:/home/aimalz/Documents/References/storage/6TYNDJRV/McCloskey et al. - 2018 - Flare Forecasting Using the Evolution of McIntosh .pdf:application/pdf;arXiv.org Snapshot:/home/aimalz/Documents/References/storage/TQHUPNAT/1805.html:text/html}
}

@article{hon_deep_2018,
	title = {Deep learning classification in asteroseismology using an improved neural network: results on 15 000 {Kepler} red giants and applications to {K}2 and {TESS} data},
	volume = {476},
	issn = {0035-8711},
	shorttitle = {Deep learning classification in asteroseismology using an improved neural network},
	url = {https://academic.oup.com/mnras/article/476/3/3233/4898088},
	doi = {10.1093/mnras/sty483},
	abstract = {Abstract.  Deep learning in the form of 1D convolutional neural networks have previously been shown to be capable of efficiently classifying the evolutionary st},
	language = {en},
	number = {3},
	urldate = {2018-07-09},
	journal = {Mon Not R Astron Soc},
	author = {Hon, Marc and Stello, Dennis and Yu, Jie},
	month = may,
	year = {2018},
	pages = {3233--3244},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/ISW8CNIF/Hon et al. - 2018 - Deep learning classification in asteroseismology u.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/RY656LKK/4898088.html:text/html}
}

@article{moller_photometric_2016,
	title = {Photometric classification of type {Ia} supernovae in the {SuperNova} {Legacy} {Survey} with supervised learning},
	volume = {2016},
	issn = {1475-7516},
	url = {http://stacks.iop.org/1475-7516/2016/i=12/a=008},
	doi = {10.1088/1475-7516/2016/12/008},
	abstract = {In the era of large astronomical surveys, photometric classification of supernovae (SNe) has become an important research field due to limited spectroscopic resources for candidate follow-up and classification. In this work, we present a method to photometrically classify type Ia supernovae based on machine learning with redshifts that are derived from the SN light-curves. This method is implemented on real data from the SNLS deferred pipeline, a purely photometric pipeline that identifies SNe Ia at high-redshifts(0.2 {\textless} z {\textless} 1.1). Our method consists of two stages: feature extraction (obtaining the SN redshift from photometry and estimating light-curve shape parameters) and machine learning classification. We study the performance of different algorithms such as Random Forest and Boosted Decision Trees. We evaluate the performance using SN simulations and real data from the first 3 years of the Supernova Legacy Survey (SNLS), which contains large spectroscopically and photometrically classified type Ia samples. Using the Area Under the Curve (AUC) metric, where perfect classification is given by 1, we find that our best-performing classifier (Extreme Gradient Boosting Decision Tree) has an AUC of 0.98.We show that it is possible to obtain a large photometrically selected type Ia SN sample with an estimated contamination of less than 5\%. When applied to data from the first three years of SNLS, we obtain 529 events. We investigate the differences between classifying simulated SNe, and real SN survey data. In particular, we find that applying a thorough set of selection cuts to the SN sample is essential for good classification. This work demonstrates for the first time the feasibility of machine learning classification in a high- z SN survey with application to real SN data.},
	language = {en},
	number = {12},
	urldate = {2018-07-09},
	journal = {J. Cosmol. Astropart. Phys.},
	author = {M{\"o}ller, A. and Ruhlmann-Kleider, V. and Leloup, C. and Neveu, J. and Palanque-Delabrouille, N. and Rich, J. and Carlberg, R. and {C. Lidman} and Pritchet, C.},
	year = {2016},
	pages = {008},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/JNIMCKC5/M{\"o}ller et al. - 2016 - Photometric classification of type Ia supernovae i.pdf:application/pdf}
}

@article{hon_deep_2017,
	title = {Deep learning classification in asteroseismology},
	volume = {469},
	issn = {0035-8711},
	url = {https://academic.oup.com/mnras/article/469/4/4578/3828087},
	doi = {10.1093/mnras/stx1174},
	abstract = {Abstract.  In the power spectra of oscillating red giants, there are visually distinct features defining stars ascending the red giant branch from those that ha},
	language = {en},
	number = {4},
	urldate = {2018-07-09},
	journal = {Mon Not R Astron Soc},
	author = {Hon, Marc and Stello, Dennis and Yu, Jie},
	month = aug,
	year = {2017},
	pages = {4578--4583},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/DFNTS5WD/Hon et al. - 2017 - Deep learning classification in asteroseismology.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/Z8K42U5R/3828087.html:text/html}
}

@article{bethapudi_separation_2018,
	title = {Separation of pulsar signals from noise using supervised machine learning algorithms},
	volume = {23},
	issn = {2213-1337},
	url = {http://www.sciencedirect.com/science/article/pii/S2213133717301397},
	doi = {10.1016/j.ascom.2018.02.002},
	abstract = {We evaluate the performance of four different machine learning (ML) algorithms: an Artificial Neural Network Multi-Layer Perceptron (ANN MLP), Adaboost, Gradient Boosting Classifier (GBC), and XGBoost, for the separation of pulsars from radio frequency interference (RFI) and other sources of noise, using a dataset obtained from the post-processing of a pulsar search pipeline. This dataset was previously used for the cross-validation of the SPINN-based machine learning engine, obtained from the reprocessing of the HTRU-S survey data (Morello et~al., 2014). We have used the Synthetic Minority Over-sampling Technique (SMOTE) to deal with high-class imbalance in the dataset. We report a variety of quality scores from all four of these algorithms on both the non-SMOTE and SMOTE datasets. For all the above ML methods, we report high accuracy and G-mean for both the non-SMOTE and SMOTE cases. We study the feature importances using Adaboost, GBC, and XGBoost and also from the minimum Redundancy Maximum Relevance approach to report algorithm-agnostic feature ranking. From these methods, we find that the signal to noise of the folded profile to be the best feature. We find that all the ML algorithms report FPRs about an order of magnitude lower than the corresponding FPRs obtained in Morello et~al. (2014), for the same recall value.},
	urldate = {2018-07-09},
	journal = {Astronomy and Computing},
	author = {Bethapudi, S. and Desai, S.},
	month = apr,
	year = {2018},
	keywords = {Data analysis stars, Methods, Neutron},
	pages = {15--26},
	file = {ScienceDirect Full Text PDF:/home/aimalz/Documents/References/storage/JZHXRFZ7/Bethapudi and Desai - 2018 - Separation of pulsar signals from noise using supe.pdf:application/pdf;ScienceDirect Snapshot:/home/aimalz/Documents/References/storage/7KTDH2FT/S2213133717301397.html:text/html}
}

@article{hon_detecting_2018,
	title = {Detecting {Solar}-like {Oscillations} in {Red} {Giants} with {Deep} {Learning}},
	volume = {859},
	issn = {0004-637X},
	url = {http://stacks.iop.org/0004-637X/859/i=1/a=64},
	doi = {10.3847/1538-4357/aabfdb},
	abstract = {Time-resolved photometry of tens of thousands of red giant stars from space missions like Kepler and K 2 has created the need for automated asteroseismic analysis methods. The first and most fundamental step in such analysis is to identify which stars show oscillations. It is critical that this step be performed with no, or little, detection bias, particularly when performing subsequent ensemble analyses that aim to compare the properties of observed stellar populations with those from galactic models. However, an efficient, automated solution to this initial detection step still has not been found, meaning that expert visual inspection of data from each star is required to obtain the highest level of detections. Hence, to mimic how an expert eye analyzes the data, we use supervised deep learning to not only detect oscillations in red giants, but also to predict the location of the frequency at maximum power, $\nu$ max , by observing features in 2D images of power spectra. By training on Kepler data, we benchmark our deep-learning classifier against K 2 data that are given detections by the expert eye, achieving a detection accuracy of 98\% on K 2 Campaign 6 stars and a detection accuracy of 99\% on K 2 Campaign 3 stars. We further find that the estimated uncertainty of our deep-learning-based $\nu$ max predictions is about 5\%. This is comparable to human-level performance using visual inspection. When examining outliers, we find that the deep-learning results are more likely to provide robust $\nu$ max estimates than the classical model-fitting method.},
	language = {en},
	number = {1},
	urldate = {2018-07-09},
	journal = {ApJ},
	author = {Hon, Marc and Stello, Dennis and Zinn, Joel C.},
	year = {2018},
	pages = {64},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/IM3FA62T/Hon et al. - 2018 - Detecting Solar-like Oscillations in Red Giants wi.pdf:application/pdf}
}

@article{wu_radio_2018,
	title = {Radio {Galaxy} {Zoo}: {ClaRAN} - {A} {Deep} {Learning} {Classifier} for {Radio} {Morphologies}},
	shorttitle = {Radio {Galaxy} {Zoo}},
	url = {http://arxiv.org/abs/1805.12008},
	abstract = {The upcoming next-generation large area radio continuum surveys can expect tens of millions of radio sources, rendering the traditional method for radio morphology classification through visual inspection unfeasible. We present ClaRAN - Classifying Radio sources Automatically with Neural networks - a proof-of-concept radio source morphology classifier based upon the Faster Region-based Convolutional Neutral Networks (Faster R-CNN) method. Specifically, we train and test ClaRAN on the FIRST and WISE images from the Radio Galaxy Zoo Data Release 1 catalogue. ClaRAN provides end users with automated identification of radio source morphology classifications from a simple input of a radio image and a counterpart infrared image of the same region. ClaRAN is the first open-source, end-to-end radio source morphology classifier that is capable of locating and associating discrete and extended components of radio sources in a fast ({\textless} 200 milliseconds per image) and accurate ({\textgreater}= 90 \%) fashion. Future work will improve ClaRAN's relatively lower success rates in dealing with multi-source fields and will enable ClaRAN to identify sources on much larger fields without loss in classification accuracy.},
	urldate = {2018-07-09},
	journal = {arXiv:1805.12008 [astro-ph]},
	author = {Wu, Chen and Wong, O. Ivy and Rudnick, Lawrence and Shabala, Stanislav S. and Alger, Matthew J. and Banfield, Julie K. and Ong, Cheng Soon and White, Sarah V. and Garon, Avery F. and Norris, Ray P. and Andernach, Heinz and Tate, Jean and Lukic, Vesna and Tang, Hongming and Schawinski, Kevin and Diakogiannis, Foivos I.},
	month = may,
	year = {2018},
	note = {arXiv: 1805.12008},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
	file = {arXiv\:1805.12008 PDF:/home/aimalz/Documents/References/storage/T3JDEB7W/Wu et al. - 2018 - Radio Galaxy Zoo ClaRAN - A Deep Learning Classif.pdf:application/pdf;arXiv.org Snapshot:/home/aimalz/Documents/References/storage/T5V6TXKS/1805.html:text/html}
}

@article{bloom_automating_2012,
	title = {Automating {Discovery} and {Classification} of {Transients} and {Variable} {Stars} in the {Synoptic} {Survey} {Era}},
	volume = {124},
	issn = {1538-3873},
	url = {http://iopscience.iop.org/article/10.1086/668468/meta},
	doi = {10.1086/668468},
	language = {en},
	number = {921},
	urldate = {2018-08-16},
	journal = {PASP},
	author = {Bloom, J. S. and Richards, J. W. and Nugent, P. E. and Quimby, R. M. and Kasliwal, M. M. and Starr, D. L. and Poznanski, D. and Ofek, E. O. and Cenko, S. B. and Butler, N. R. and Kulkarni, S. R. and Gal-Yam, A. and Law, N.},
	month = oct,
	year = {2012},
	pages = {1175},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/BVL9JNXC/Bloom et al. - 2012 - Automating Discovery and Classification of Transie.pdf:application/pdf;Full Text PDF:/home/aimalz/Documents/References/storage/XVVKA5YG/Bloom et al. - 2012 - Automating Discovery and Classification of Transie.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/ZFI2SUZP/668468.html:text/html;Snapshot:/home/aimalz/Documents/References/storage/HFCLT7G2/668468.html:text/html}
}

@article{hoyle_measuring_2016,
	title = {Measuring photometric redshifts using galaxy images and {Deep} {Neural} {Networks}},
	volume = {16},
	issn = {2213-1337},
	url = {http://www.sciencedirect.com/science/article/pii/S221313371630021X},
	doi = {10.1016/j.ascom.2016.03.006},
	abstract = {We propose a new method to estimate the photometric redshift of galaxies by using the full galaxy image in each measured band. This method draws from the latest techniques and advances in machine learning, in particular Deep Neural Networks. We pass the entire multi-band galaxy image into the machine learning architecture to obtain a redshift estimate that is competitive, in terms of the measured point prediction metrics, with the best existing standard machine learning techniques. The standard techniques estimate redshifts using post-processed features, such as magnitudes and colours, which are extracted from the galaxy images and are deemed to be salient by the user. This new method removes the user from the photometric redshift estimation pipeline. However we do note that Deep Neural Networks require many orders of magnitude more computing resources than standard machine learning architectures, and as such are only tractable for making predictions on datasets of size <=50k before implementing parallelisation techniques.},
	urldate = {2018-08-20},
	journal = {Astronomy and Computing},
	author = {Hoyle, B.},
	month = jul,
	year = {2016},
	keywords = {Astronomy, Cosmology, Machine learning},
	pages = {34--40},
	file = {ScienceDirect Full Text PDF:/home/aimalz/Documents/References/storage/E3CQ42DJ/Hoyle - 2016 - Measuring photometric redshifts using galaxy image.pdf:application/pdf;ScienceDirect Snapshot:/home/aimalz/Documents/References/storage/MJDVU6JS/S221313371630021X.html:text/html}
}

@book{murphy_machine_2012,
	title = {Machine learning: a probabilistic perspective},
	isbn = {0-262-01802-0 978-0-262-01802-9},
	publisher = {The MIT Press},
	author = {Murphy, Kevin P.},
	year = {2012}
}

@inproceedings{djorgovski_flashes_2012,
	title = {Flashes in a star stream: {Automated} classification of astronomical transient events},
	shorttitle = {Flashes in a star stream},
	doi = {10.1109/eScience.2012.6404437},
	abstract = {An automated, rapid classification of transient events detected in the modern synoptic sky surveys is essential for their scientific utility and effective follow-up using scarce resources. This presents some unusual challenges: the data are sparse, heterogeneous and incomplete; evolving in time; and most of the relevant information comes not from the data stream itself, but from a variety of archival data and contextual information (spatial, temporal, and multi-wavelength). We are exploring a variety of novel techniques, mostly Bayesian, to respond to these challenges, using the ongoing CRTS sky survey as a testbed. The current surveys are already overwhelming our ability to effectively follow all of the potentially interesting events, and these challenges will grow by orders of magnitude over the next decade as the more ambitious sky surveys get under way. While we focus on an application in a specific domain (astrophysics), these challenges are more broadly relevant for event or anomaly detection and knowledge discovery in massive data streams.},
	booktitle = {2012 {IEEE} 8th {International} {Conference} on {E}-{Science}},
	author = {Djorgovski, S. G. and Mahabal, A. A. and Donalek, C. and Graham, M. J. and Drake, A. J. and Moghaddam, B. and Turmon, M.},
	month = oct,
	year = {2012},
	keywords = {data mining, machine learning, astronomy computing, pattern classification, Transient analysis, anomaly detection, archival data, astronomical techniques, astrophysics, automated astronomical transient event classification, automated decision making, Bayes methods, Bayesian methods, Bayesian technique, classification, contextual information, CRTS sky survey, event detection, Extraterrestrial measurements, Histograms, Image color analysis, knowledge discovery, massive data streams, multiwavelength information, Pollution measurement, Real-time systems, sky surveys, spatial information, star stream, stars, synoptic sky surveys, temporal information},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:/home/aimalz/Documents/References/storage/XFJKEV3Q/6404437.html:text/html;IEEE Xplore Full Text PDF:/home/aimalz/Documents/References/storage/FPNA9G7Q/Djorgovski et al. - 2012 - Flashes in a star stream Automated classification.pdf:application/pdf}
}

@article{conley_sifto:_2008,
	title = {{SiFTO}: {An} {Empirical} {Method} for {Fitting} {SN} {Ia} {Light} {Curves}},
	volume = {681},
	issn = {0004-637X},
	shorttitle = {{SiFTO}},
	url = {http://stacks.iop.org/0004-637X/681/i=1/a=482},
	doi = {10.1086/588518},
	abstract = {We present SiFTO, a new empirical method for modeling Type Ia supernova (SN Ia) light curves by manipulating a spectral template. We make use of high-redshift SN data when training the model, allowing us to extend it bluer than rest-frame U . This increases the utility of our high-redshift SN observations by allowing us to use more of the available data. We find that when the shape of the light curve is described using a stretch prescription, applying the same stretch at all wavelengths is not an adequate description. SiFTO therefore uses a generalization of stretch which applies different stretch factors as a function of both the wavelength of the observed filter and the stretch in the rest-frame B band. We compare SiFTO to other published light-curve models by applying them to the same set of SN photometry, and demonstrate that SiFTO and SALT2 perform better than the alternatives when judged by the scatter around the best-fit luminosity distance relationship. We further demonstrate that when SiFTO and SALT2 are trained on the same data set the cosmological results agree.},
	language = {en},
	number = {1},
	urldate = {2018-08-20},
	journal = {ApJ},
	author = {Conley, A. and Sullivan, M. and Hsiao, E. Y. and Guy, J. and Astier, P. and Balam, D. and Balland, C. and Basa, S. and Carlberg, R. G. and {D. Fouchez} and Hardin, D. and Howell, D. A. and Hook, I. M. and Pain, R. and Perrett, K. and Pritchet, C. J. and Regnault, N.},
	year = {2008},
	pages = {482},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/XZPXXY6A/Conley et al. - 2008 - SiFTO An Empirical Method for Fitting SN Ia Light.pdf:application/pdf}
}

@article{djorgovski_towards_2011,
	title = {Towards an {Automated} {Classification} of {Transient} {Events} in {Synoptic} {Sky} {Surveys}},
	url = {http://arxiv.org/abs/1110.4655},
	abstract = {We describe the development of a system for an automated, iterative, real-time classification of transient events discovered in synoptic sky surveys. The system under development incorporates a number of Machine Learning techniques, mostly using Bayesian approaches, due to the sparse nature, heterogeneity, and variable incompleteness of the available data. The classifications are improved iteratively as the new measurements are obtained. One novel feature is the development of an automated follow-up recommendation engine, that suggest those measurements that would be the most advantageous in terms of resolving classification ambiguities and/or characterization of the astrophysically most interesting objects, given a set of available follow-up assets and their cost functions. This illustrates the symbiotic relationship of astronomy and applied computer science through the emerging discipline of AstroInformatics.},
	urldate = {2018-08-20},
	journal = {arXiv:1110.4655 [astro-ph, physics:physics]},
	author = {Djorgovski, S. G. and Donalek, C. and Mahabal, A. and Moghaddam, B. and Turmon, M. and Graham, M. and Drake, A. and Sharma, N. and Chen, Y.},
	month = oct,
	year = {2011},
	note = {arXiv: 1110.4655},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Physics - Computational Physics},
	file = {arXiv\:1110.4655 PDF:/home/aimalz/Documents/References/storage/KQCNRECI/Djorgovski et al. - 2011 - Towards an Automated Classification of Transient E.pdf:application/pdf;arXiv.org Snapshot:/home/aimalz/Documents/References/storage/CN3C7NU5/1110.html:text/html}
}

@article{nugent_kcorrections_2002,
	title = {K-{Corrections} and {Extinction} {Corrections} for {Type} {Ia} {Supernovae}},
	volume = {114},
	issn = {1538-3873},
	url = {http://iopscience.iop.org/article/10.1086/341707/meta},
	doi = {10.1086/341707},
	language = {en},
	number = {798},
	urldate = {2018-08-20},
	journal = {PASP},
	author = {Nugent, Peter and Kim, Alex and Perlmutter, Saul},
	month = jul,
	year = {2002},
	pages = {803},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/YB84G6IY/Nugent et al. - 2002 - K-Corrections and Extinction Corrections for Type .pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/ZH662SVM/341707.html:text/html}
}

@article{malz_approximating_2018,
	title = {Approximating {Photo}- z {PDFs} for {Large} {Surveys}},
	volume = {156},
	issn = {1538-3881},
	url = {http://stacks.iop.org/1538-3881/156/i=1/a=35},
	doi = {10.3847/1538-3881/aac6b5},
	abstract = {Modern galaxy surveys produce redshift probability density functions (PDFs) in addition to traditional photometric redshift (photo- z ) point estimates. However, the storage of photo- z PDFs may present a challenge with increasingly large catalogs, as we face a trade-off between the accuracy of subsequent science measurements and the limitation of finite storage resources. This paper presents qp , a Python package for manipulating parameterizations of one-dimensional PDFs, as suitable for photo- z PDF compression. We use qp to investigate the performance of three simple PDF storage formats (quantiles, samples, and step functions) as a function of the number of stored parameters on two realistic mock data sets, representative of upcoming surveys with different data qualities. We propose some best practices for choosing a photo- z PDF approximation scheme and demonstrate the approach on a science case using performance metrics on both ensembles of individual photo- z PDFs and an estimator of the overall redshift distribution function. We show that both the properties of the set of PDFs we wish to approximate and the fidelity metric(s) chosen affect the optimal parameterization. Additionally, we find that quantiles and samples outperform step functions, and we encourage further consideration of these formats for PDF approximation.},
	language = {en},
	number = {1},
	urldate = {2018-08-20},
	journal = {AJ},
	author = {Malz, A. I. and Marshall, P. J. and DeRose, J. and Graham, M. L. and Schmidt, S. J. and Wechsler, R. and Collaboration), (LSST Dark Energy Science},
	year = {2018},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
	pages = {35},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/JGQ7SQMS/Malz et al. - 2018 - Approximating Photo- z PDFs for Large Surveys.pdf:application/pdf;IOP Full Text PDF:/home/aimalz/Documents/References/storage/3F6SH9YS/Malz et al. - 2018 - Approximating Photo- z PDFs for Large Surveys.pdf:application/pdf}
}

@inproceedings{mahabal_deep-learnt_2017,
	title = {Deep-learnt classification of light curves},
	doi = {10.1109/SSCI.2017.8280984},
	abstract = {Astronomy light curves are sparse, gappy, and heteroscedastic. As a result standard time series methods regularly used for financial and similar datasets are of little help and astronomers are usually left to their own instruments and techniques to classify light curves. A common approach is to derive statistical features from the time series and to use machine learning methods, generally supervised, to separate objects into a few of the standard classes. In this work, we transform the time series to two-dimensional light curve representations in order to classify them using modern deep learning techniques. In particular, we show that convolutional neural networks based classifiers work well for broad characterization and classification. We use labeled datasets of periodic variables from CRTS survey and show how this opens doors for a quick classification of diverse classes with several possible exciting extensions.},
	booktitle = {2017 {IEEE} {Symposium} {Series} on {Computational} {Intelligence} ({SSCI})},
	author = {Mahabal, A. and Sheth, K. and Gieseke, F. and Pai, A. and Djorgovski, S. G. and Drake, A. J. and Graham, M. J.},
	month = nov,
	year = {2017},
	keywords = {astronomers, Astronomy, astronomy computing, astronomy light curves, Cathode ray tubes, convolutional neural networks based classifiers work, data analysis, deep-learnt classification, financial datasets, instruments, Kernel, labeled datasets, learning (artificial intelligence), machine learning methods, modern deep learning techniques, neural nets, pattern classification, periodic variables, standard classes, standard time series methods, Standards, statistical features, time series, Time series analysis, Training, Transient analysis, two-dimensional light curve representations},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:/home/aimalz/Documents/References/storage/QZQDB89Z/8280984.html:text/html;IEEE Xplore Full Text PDF:/home/aimalz/Documents/References/storage/PWM3FB3J/Mahabal et al. - 2017 - Deep-learnt classification of light curves.pdf:application/pdf}
}

@article{charnock_deep_2017,
	title = {Deep {Recurrent} {Neural} {Networks} for {Supernovae} {Classification}},
	volume = {837},
	issn = {2041-8205},
	url = {http://stacks.iop.org/2041-8205/837/i=2/a=L28},
	doi = {10.3847/2041-8213/aa603d},
	abstract = {We apply deep recurrent neural networks, which are capable of learning complex sequential information, to classify supernovae (code available at https://github.com/adammoss/supernovae). The observational time and filter fluxes are used as inputs to the network, but since the inputs are agnostic, additional data such as host galaxy information can also be included. Using the Supernovae Photometric Classification Challenge (SPCC) data, we find that deep networks are capable of learning about light curves, however the performance of the network is highly sensitive to the amount of training data. For a training size of 50\% of the representational SPCC data set (around 10 4 supernovae) we obtain a type-Ia versus non-type-Ia classification accuracy of 94.7\%, an area under the Receiver Operating Characteristic curve AUC of 0.986 and an SPCC figure-of-merit F 1 = 0.64. When using only the data for the early-epoch challenge defined by the SPCC, we achieve a classification accuracy of 93.1\%, AUC of 0.977, and F 1 = 0.58, results almost as good as with the whole light curve. By employing bidirectional neural networks, we can acquire impressive classification results between supernovae types I, II and III at an accuracy of 90.4\% and AUC of 0.974. We also apply a pre-trained model to obtain classification probabilities as a function of time and show that it can give early indications of supernovae type. Our method is competitive with existing algorithms and has applications for future large-scale photometric surveys.},
	language = {en},
	number = {2},
	urldate = {2018-08-20},
	journal = {ApJL},
	author = {Charnock, Tom and Moss, Adam},
	year = {2017},
	pages = {L28},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/2287WY74/Charnock and Moss - 2017 - Deep Recurrent Neural Networks for Supernovae Clas.pdf:application/pdf}
}

@article{george_classification_2018,
	title = {Classification and unsupervised clustering of {LIGO} data with {Deep} {Transfer} {Learning}},
	volume = {97},
	url = {https://link.aps.org/doi/10.1103/PhysRevD.97.101501},
	doi = {10.1103/PhysRevD.97.101501},
	abstract = {Gravitational wave detection requires a detailed understanding of the response of the LIGO and Virgo detectors to true signals in the presence of environmental and instrumental noise. Of particular interest is the study of anomalous non-Gaussian transients, such as glitches, since their occurrence rate in LIGO and Virgo data can obscure or even mimic true gravitational wave signals. Therefore, successfully identifying and excising these anomalies from gravitational wave data is of utmost importance for the detection and characterization of true signals and for the accurate computation of their significance. To facilitate this work, we present the first application of deep learning combined with transfer learning to show that knowledge from pretrained models for real-world object recognition can be transferred for classifying spectrograms of glitches. To showcase this new method, we use a data set of twenty-two classes of glitches, curated and labeled by the Gravity Spy project using data collected during LIGO{\textquoteright}s first discovery campaign. We demonstrate that our Deep Transfer Learning method enables an optimal use of very deep convolutional neural networks for glitch classification given small and unbalanced training data sets, significantly reduces the training time, and achieves state-of-the-art accuracy above 98.8\%, lowering the previous error rate by over 60\%. More importantly, once trained via transfer learning on the known classes, we show that our neural networks can be truncated and used as feature extractors for unsupervised clustering to automatically group together new unknown classes of glitches and anomalous signals. This novel capability is of paramount importance to identify and remove new types of glitches which will occur as the LIGO/Virgo detectors gradually attain design sensitivity.},
	number = {10},
	urldate = {2018-08-20},
	journal = {Phys. Rev. D},
	author = {George, Daniel and Shen, Hongyu and Huerta, E. A.},
	month = may,
	year = {2018},
	pages = {101501},
	file = {APS Snapshot:/home/aimalz/Documents/References/storage/9KPPZLWX/PhysRevD.97.html:text/html;PhysRevD.97.101501.pdf:/home/aimalz/Documents/References/storage/AG3P8877/PhysRevD.97.101501.pdf:application/pdf}
}

@article{zevin_gravity_2017,
	title = {Gravity {Spy}: integrating advanced {LIGO} detector characterization, machine learning, and citizen science},
	volume = {34},
	issn = {0264-9381},
	shorttitle = {Gravity {Spy}},
	url = {http://stacks.iop.org/0264-9381/34/i=6/a=064003},
	doi = {10.1088/1361-6382/aa5cea},
	abstract = {With the first direct detection of gravitational waves, the advanced laser interferometer gravitational-wave observatory (LIGO) has initiated a new field of astronomy by providing an alternative means of sensing the universe. The extreme sensitivity required to make such detections is achieved through exquisite isolation of all sensitive components of LIGO from non-gravitational-wave disturbances. Nonetheless, LIGO is still susceptible to a variety of instrumental and environmental sources of noise that contaminate the data. Of particular concern are noise features known as glitches , which are transient and non-Gaussian in their nature, and occur at a high enough rate so that accidental coincidence between the two LIGO detectors is non-negligible. Glitches come in a wide range of time-frequency-amplitude morphologies, with new morphologies appearing as the detector evolves. Since they can obscure or mimic true gravitational-wave signals, a robust characterization of glitches is paramount in the effort to achieve the gravitational-wave detection rates that are predicted by the design sensitivity of LIGO. This proves a daunting task for members of the LIGO Scientific Collaboration alone due to the sheer amount of data. In this paper we describe an innovative project that combines crowdsourcing with machine learning to aid in the challenging task of categorizing all of the glitches recorded by the LIGO detectors. Through the Zooniverse platform, we engage and recruit volunteers from the public to categorize images of time-frequency representations of glitches into pre-identified morphological classes and to discover new classes that appear as the detectors evolve. In addition, machine learning algorithms are used to categorize images after being trained on human-classified examples of the morphological classes. Leveraging the strengths of both classification methods, we create a combined method with the aim of improving the efficiency and accuracy of each individual classifier. The resulting classification and characterization should help LIGO scientists to identify causes of glitches and subsequently eliminate them from the data or the detector entirely, thereby improving the rate and accuracy of gravitational-wave observations. We demonstrate these methods using a small subset of data from LIGO{\textquoteright}s first observing run.},
	language = {en},
	number = {6},
	urldate = {2018-08-20},
	journal = {Class. Quantum Grav.},
	author = {Zevin, M. and Coughlin, S. and Bahaadini, S. and Besler, E. and Rohani, N. and Allen, S. and Cabero, M. and Crowston, K. and Katsaggelos, A. K. and Larson, S. L. and Lee, T. K. and Lintott, C. and Littenberg, T. B. and Lundgren, A. and {\O}sterlund, C. and Smith, J. R. and Trouille, L. and Kalogera, V.},
	year = {2017},
	pages = {064003},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/DNG4D3B7/Zevin et al. - 2017 - Gravity Spy integrating advanced LIGO detector ch.pdf:application/pdf}
}

@article{morii_machine-learning_2016,
	title = {Machine-learning selection of optical transients in the {Subaru}/{Hyper} {Suprime}-{Cam} survey},
	volume = {68},
	issn = {0004-6264},
	url = {https://academic.oup.com/pasj/article/68/6/104/2433400},
	doi = {10.1093/pasj/psw096},
	abstract = {Abstract.  We present an application of machine-learning (ML) techniques to source selection in the optical transient survey data with the Hyper Suprime-Cam (HS},
	language = {en},
	number = {6},
	urldate = {2018-08-20},
	journal = {Publ Astron Soc Jpn Nihon Tenmon Gakkai},
	author = {Morii, Mikio and Ikeda, Shiro and Tominaga, Nozomu and Tanaka, Masaomi and Morokuma, Tomoki and Ishiguro, Katsuhiko and Yamato, Junji and Ueda, Naonori and Suzuki, Naotaka and Yasuda, Naoki and Yoshida, Naoki},
	month = dec,
	year = {2016},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/BYILWI7C/Morii et al. - 2016 - Machine-learning selection of optical transients i.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/VI5RGDVC/2433400.html:text/html}
}

@article{abraham_detection_2018,
	title = {Detection of bars in galaxies using a deep convolutional neural network},
	volume = {477},
	issn = {0035-8711},
	url = {https://academic.oup.com/mnras/article/477/1/894/4925012},
	doi = {10.1093/mnras/sty627},
	abstract = {Abstract.  We present an automated method for the detection of bar structure in optical images of galaxies using a deep convolutional neural network that is eas},
	language = {en},
	number = {1},
	urldate = {2018-08-20},
	journal = {Mon Not R Astron Soc},
	author = {Abraham, Sheelu and Aniyan, A. K. and Kembhavi, Ajit K. and Philip, N. S. and Vaghmare, Kaustubh},
	month = jun,
	year = {2018},
	pages = {894--903},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/E2RMQLMR/Abraham et al. - 2018 - Detection of bars in galaxies using a deep convolu.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/NNL43G6E/4925012.html:text/html}
}

@article{cabrera-vives_deep-hits:_2017,
	title = {Deep-{HiTS}: {Rotation} {Invariant} {Convolutional} {Neural} {Network} for {Transient} {Detection}},
	volume = {836},
	issn = {0004-637X},
	shorttitle = {Deep-{HiTS}},
	url = {http://stacks.iop.org/0004-637X/836/i=1/a=97},
	doi = {10.3847/1538-4357/836/1/97},
	abstract = {We introduce Deep-HiTS, a rotation-invariant convolutional neural network (CNN) model for classifying images of transient candidates into artifacts or real sources for the High cadence Transient Survey (HiTS). CNNs have the advantage of learning the features automatically from the data while achieving high performance. We compare our CNN model against a feature engineering approach using random forests (RFs). We show that our CNN significantly outperforms the RF model, reducing the error by almost half. Furthermore, for a fixed number of approximately 2000 allowed false transient candidates per night, we are able to reduce the misclassified real transients by approximately one-fifth. To the best of our knowledge, this is the first time CNNs have been used to detect astronomical transient events. Our approach will be very useful when processing images from next generation instruments such as the Large Synoptic Survey Telescope. We have made all our code and data available to the community for the sake of allowing further developments and comparisons at https://github.com/guille-c/Deep-HiTS [http://https://github.com/guille-c/Deep-HiTS] .},
	language = {en},
	number = {1},
	urldate = {2018-08-20},
	journal = {ApJ},
	author = {Cabrera-Vives, Guillermo and Reyes, Ignacio and F{\"o}rster, Francisco and Est{\'e}vez, Pablo A. and Maureira, Juan-Carlos},
	year = {2017},
	pages = {97},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/B2T9X48G/Cabrera-Vives et al. - 2017 - Deep-HiTS Rotation Invariant Convolutional Neural.pdf:application/pdf}
}

@article{newling_statistical_2011,
	title = {Statistical classification techniques for photometric supernova typing},
	volume = {414},
	issn = {0035-8711},
	url = {https://academic.oup.com/mnras/article/414/3/1987/1035457},
	doi = {10.1111/j.1365-2966.2011.18514.x},
	abstract = {Abstract.  Future photometric supernova surveys will produce vastly more candidates than can be followed up spectroscopically, highlighting the need for effecti},
	language = {en},
	number = {3},
	urldate = {2018-08-20},
	journal = {Mon Not R Astron Soc},
	author = {Newling, J. and Varughese, M. and Bassett, B. and Campbell, H. and Hlozek, R. and Kunz, M. and Lampeitl, H. and Martin, B. and Nichol, R. and Parkinson, D. and Smith, M.},
	month = jul,
	year = {2011},
	pages = {1987--2004},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/2QH7KF5N/Newling et al. - 2011 - Statistical classification techniques for photomet.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/M75AJHC2/1035457.html:text/html}
}

@article{sako_photometric_2011,
	title = {Photometric {Type} {Ia} {Supernova} {Candidates} from the {Three}-year {SDSS}-{II} {SN} {Survey} {Data}},
	volume = {738},
	issn = {0004-637X},
	url = {http://stacks.iop.org/0004-637X/738/i=2/a=162},
	doi = {10.1088/0004-637X/738/2/162},
	abstract = {We analyze the three-year Sloan Digital Sky Survey II (SDSS-II) Supernova (SN) Survey data and identify a sample of 1070 photometric Type Ia supernova (SN Ia) candidates based on their multiband light curve data. This sample consists of SN candidates with no spectroscopic confirmation, with a subset of 210 candidates having spectroscopic redshifts of their host galaxies measured while the remaining 860 candidates are purely photometric in their identification. We describe a method for estimating the efficiency and purity of photometric SN Ia classification when spectroscopic confirmation of only a limited sample is available, and demonstrate that SN Ia candidates from SDSS-II can be identified photometrically with 91\% efficiency and with a contamination of 6\%. Although this is the largest uniform sample of SN candidates to date for studying photometric identification, we find that a larger spectroscopic sample of contaminating sources is required to obtain a better characterization of the background events. A Hubble diagram using SN candidates with no spectroscopic confirmation, but with host galaxy spectroscopic redshifts, yields a distance modulus dispersion that is only 20\%-40\% larger than that of the spectroscopically confirmed SN Ia sample alone with no significant bias. A Hubble diagram with purely photometric classification and redshift-distance measurements, however, exhibits biases that require further investigation for precision cosmology.},
	language = {en},
	number = {2},
	urldate = {2018-08-20},
	journal = {ApJ},
	author = {Sako, Masao and Bassett, Bruce and Connolly, Brian and Dilday, Benjamin and Cambell, Heather and Frieman, Joshua A. and {Larry Gladney} and Kessler, Richard and Lampeitl, Hubert and Marriner, John and Miquel, Ramon and Nichol, Robert C. and Schneider, Donald P. and Smith, Mathew and Sollerman, Jesper},
	year = {2011},
	pages = {162},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/HGVZPA9D/Sako et al. - 2011 - Photometric Type Ia Supernova Candidates from the .pdf:application/pdf}
}

@inproceedings{gieseke_detecting_2010,
	title = {Detecting {Quasars} in {Large}-{Scale} {Astronomical} {Surveys}},
	doi = {10.1109/ICMLA.2010.59},
	abstract = {We present a classification-based approach to identify quasi-stellar radio sources (quasars) in the Sloan Digital Sky Survey and evaluate its performance on a manually labeled training set. While reasonable results can already be obtained via approaches working only on photometric data, our experiments indicate that simple but problem-specific features extracted from spectroscopic data can significantly improve the classification performance. Since our approach works orthogonal to existing classification schemes used for building the spectroscopic catalogs, our classification results are well suited for a mutual assessment of the approaches' accuracies.},
	booktitle = {2010 {Ninth} {International} {Conference} on {Machine} {Learning} and {Applications}},
	author = {Gieseke, F. and Polsterer, K. L. and Thom, A. and Zinn, P. and Bomanns, D. and Dettmar, R. and Kramer, O. and Vahrenhold, J.},
	month = dec,
	year = {2010},
	keywords = {machine learning, Astronomy, astronomy computing, data analysis, Kernel, learning (artificial intelligence), Training, quasars, classification, astronomical catalogues, astronomical photometry, astronomical surveys, astronomy, classification performance, classification schemes, classification-based approach, Data models, detecting quasars, feature extraction, Feature extraction, large-scale astronomical surveys, manually labeled training set, performance evaluation, photometric data, problem-specific features extraction, quasi-stellar radio sources, sloan digital sky survey, spectroscopic catalogs, spectroscopic data, Spline, Support vector machines},
	pages = {352--357},
	file = {IEEE Xplore Abstract Record:/home/aimalz/Documents/References/storage/K8HRKBJ5/5708856.html:text/html;IEEE Xplore Full Text PDF:/home/aimalz/Documents/References/storage/XUN45HCA/Gieseke et al. - 2010 - Detecting Quasars in Large-Scale Astronomical Surv.pdf:application/pdf}
}

@article{kitching_gravitational_2011,
	title = {Gravitational {Lensing} {Accuracy} {Testing} 2010 ({GREAT}10) {Challenge} {Handbook}},
	volume = {5},
	issn = {1932-6157, 1941-7330},
	url = {https://projecteuclid.org/euclid.aoas/1318514302},
	doi = {10.1214/11-AOAS484},
	abstract = {GRavitational lEnsing Accuracy Testing 2010 (GREAT10) is a public image analysis challenge aimed at the development of algorithms to analyze astronomical images. Specifically, the challenge is to measure varying image distortions in the presence of a variable convolution kernel, pixelization and noise. This is the second in a series of challenges set to the astronomy, computer science and statistics communities, providing a structured environment in which methods can be improved and tested in preparation for planned astronomical surveys. GREAT10 extends upon previous work by introducing variable fields into the challenge. The {\textquotedblleft}Galaxy Challenge{\textquotedblright} involves the precise measurement of galaxy shape distortions, quantified locally by two parameters called shear, in the presence of a known convolution kernel. Crucially, the convolution kernel and the simulated gravitational lensing shape distortion both now vary as a function of position within the images, as is the case for real data. In addition, we introduce the {\textquotedblleft}Star Challenge{\textquotedblright} that concerns the reconstruction of a variable convolution kernel, similar to that in a typical astronomical observation. This document details the GREAT10 Challenge for potential participants. Continually updated information is also available from www.greatchallenges.info.},
	language = {EN},
	number = {3},
	urldate = {2018-08-21},
	journal = {Ann. Appl. Stat.},
	author = {Kitching, Thomas and Amara, Adam and Gill, Mandeep and Harmeling, Stefan and Heymans, Catherine and Massey, Richard and Rowe, Barnaby and Schrabback, Tim and Voigt, Lisa and Balan, Sreekumar and Bernstein, Gary and Bethge, Matthias and Bridle, Sarah and Courbin, Frederic and Gentile, Marc and Heavens, Alan and Hirsch, Michael and Hosseini, Reshad and Kiessling, Alina and Kirk, Donnacha and Kuijken, Konrad and Mandelbaum, Rachel and Moghaddam, Baback and Nurbaeva, Guldariya and Paulin-Henriksson, Stephane and Rassat, Anais and Rhodes, Jason and Sch{\"o}lkopf, Bernhard and Shawe-Taylor, John and Shmakova, Marina and Taylor, Andy and Velander, Malin and Waerbeke, Ludovic van and Witherick, Dugan and Wittman, David},
	month = sep,
	year = {2011},
	mrnumber = {MR2884938},
	zmnumber = {1228.62164},
	keywords = {cosmology, imaging processing, Statistical inference},
	pages = {2231--2263},
	file = {Snapshot:/home/aimalz/Documents/References/storage/IA4I3VDH/1318514302.html:text/html}
}

@article{harvey_observing_2013,
	title = {Observing {Dark} {Worlds}: {A} crowdsourcing experiment for dark matter mapping},
	shorttitle = {Observing {Dark} {Worlds}},
	url = {http://arxiv.org/abs/1311.0704},
	abstract = {We present the results and conclusions from the citizen science competition `Observing Dark Worlds', where we asked participants to calculate the positions of dark matter halos from 120 catalogues of simulated weak lensing galaxy data, using computational methods. In partnership with Kaggle (http://www.kaggle.com), 357 users participated in the competition which saw 2278 downloads of the data and 3358 submissions. We found that the best algorithms improved on the benchmark code, LENSTOOL by {\textgreater} 30\% and could measure the positions of {\textgreater} 3x10{\textasciicircum}14MSun halos to less than 5'' and {\textless} 10{\textasciicircum}14MSun to within 1'. In this paper, we present a brief overview of the winning algorithms with links to available code. We also discuss the implications of the experiment for future citizen science competitions.},
	urldate = {2018-08-21},
	journal = {arXiv:1311.0704 [astro-ph, physics:physics]},
	author = {Harvey, David and Kitching, Thomas D. and Noah-Vanhoucke, Joyce and Hamner, Ben and Salimans, Tim},
	month = nov,
	year = {2013},
	note = {arXiv: 1311.0704},
	keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - Instrumentation and Methods for Astrophysics, Physics - Physics and Society},
	file = {arXiv\:1311.0704 PDF:/home/aimalz/Documents/References/storage/EKMGZ6CP/Harvey et al. - 2013 - Observing Dark Worlds A crowdsourcing experiment .pdf:application/pdf;arXiv.org Snapshot:/home/aimalz/Documents/References/storage/CZF3PAY2/1311.html:text/html}
}

@article{dieleman_rotation-invariant_2015,
	title = {Rotation-invariant convolutional neural networks for galaxy morphology prediction},
	volume = {450},
	issn = {0035-8711},
	url = {https://academic.oup.com/mnras/article/450/2/1441/979677},
	doi = {10.1093/mnras/stv632},
	abstract = {Abstract.  Measuring the morphological parameters of galaxies is a key requirement for studying their formation and evolution. Surveys such as the Sloan Digital},
	language = {en},
	number = {2},
	urldate = {2018-08-21},
	journal = {Mon Not R Astron Soc},
	author = {Dieleman, Sander and Willett, Kyle W. and Dambre, Joni},
	month = jun,
	year = {2015},
	pages = {1441--1459},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/7H75PH6C/Dieleman et al. - 2015 - Rotation-invariant convolutional neural networks f.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/2UELU548/979677.html:text/html}
}

@article{mandelbaum_third_2014,
	title = {The {Third} {Gravitational} {Lensing} {Accuracy} {Testing} ({GREAT}3) {Challenge} {Handbook}},
	volume = {212},
	issn = {0067-0049},
	url = {http://stacks.iop.org/0067-0049/212/i=1/a=5},
	doi = {10.1088/0067-0049/212/1/5},
	abstract = {The GRavitational lEnsing Accuracy Testing 3 (GREAT3) challenge is the third in a series of image analysis challenges, with a goal of testing and facilitating the development of methods for analyzing astronomical images that will be used to measure weak gravitational lensing. This measurement requires extremely precise estimation of very small galaxy shape distortions, in the presence of far larger intrinsic galaxy shapes and distortions due to the blurring kernel caused by the atmosphere, telescope optics, and instrumental effects. The GREAT3 challenge is posed to the astronomy, machine learning, and statistics communities, and includes tests of three specific effects that are of immediate relevance to upcoming weak lensing surveys, two of which have never been tested in a community challenge before. These effects include many novel aspects including realistically complex galaxy models based on high-resolution imaging from space; a spatially varying, physically motivated blurring kernel; and a combination of multiple different exposures. To facilitate entry by people new to the field, and for use as a diagnostic tool, the simulation software for the challenge is publicly available, though the exact parameters used for the challenge are blinded. Sample scripts to analyze the challenge data using existing methods will also be provided. See http://great3challenge.info [http://great3challenge.info] and http://great3.projects.phys.ucl.ac.uk/leaderboard/ [http://great3.projects.phys.ucl.ac.uk/leaderboard/] for more information.},
	language = {en},
	number = {1},
	urldate = {2018-08-21},
	journal = {ApJS},
	author = {Mandelbaum, Rachel and Rowe, Barnaby and Bosch, James and Chang, Chihway and Courbin, Frederic and Gill, Mandeep and {Mike Jarvis} and Kannawadi, Arun and Kacprzak, Tomasz and Lackner, Claire and Leauthaud, Alexie and Miyatake, Hironao and {Reiko Nakajima} and Rhodes, Jason and Simet, Melanie and Zuntz, Joe and Armstrong, Bob and Bridle, Sarah and Coupon, Jean and Dietrich, J{\"o}rg P. and Gentile, Marc and Heymans, Catherine and Jurling, Alden S. and Kent, Stephen M. and Kirkby, David and {Daniel Margala} and Massey, Richard and Melchior, Peter and Peterson, John and Roodman, Aaron and Schrabback, Tim},
	year = {2014},
	pages = {5},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/LNU8XNI8/Mandelbaum et al. - 2014 - The Third Gravitational Lensing Accuracy Testing (.pdf:application/pdf}
}

@article{mahabal_automated_2008,
	title = {Automated probabilistic classification of transients and variables},
	volume = {329},
	copyright = {Copyright {\textcopyright} 2008 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
	issn = {1521-3994},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asna.200710943},
	doi = {10.1002/asna.200710943},
	abstract = {There is an increasing number of large, digital, synoptic sky surveys, in which repeated observations are obtained over large areas of the sky in multiple epochs. Likewise, there is a growth in the number of (often automated or robotic) follow-up facilities with varied capabilities in terms of instruments, depth, cadence, wavelengths, etc., most of which are geared toward some specific astrophysical phenomenon. As the number of detected transient events grows, an automated, probabilistic classification of the detected variables and transients becomes increasingly important, so that an optimal use can be made of follow-up facilities, without unnecessary duplication of effort. We describe a methodology now under development for a prototype event classification system; it involves Bayesian and Machine Learning classifiers, automated incorporation of feedback from follow-up observations, and discriminated or directed follow-up requests. This type of methodology may be essential for the massive synoptic sky surveys in the future. ({\textcopyright} 2008 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim)},
	language = {en},
	number = {3},
	urldate = {2018-10-04},
	journal = {Astronomische Nachrichten},
	author = {Mahabal, A. and Djorgovski, S. G. and Turmon, M. and Jewell, J. and Williams, R. R. and Drake, A. J. and Graham, M. G. and Donalek, C. and Glikman, E. and Team, Palomar-QUEST},
	month = mar,
	year = {2008},
	keywords = {surveys, methods: data analysis, methods: statistical, astronomical databases: miscellaneous},
	pages = {288--291},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/E3QFUK24/Mahabal et al. - 2008 - Automated probabilistic classification of transien.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/GBY4QAIM/asna.html:text/html}
}

@article{rubin_unity:_2015,
	title = {{UNITY}: {Confronting} {Supernova} {Cosmology}'s {Statistical} and {Systematic} {Uncertainties} in a {Unified} {Bayesian} {Framework}},
	volume = {813},
	issn = {0004-637X},
	shorttitle = {{UNITY}},
	url = {http://stacks.iop.org/0004-637X/813/i=2/a=137},
	doi = {10.1088/0004-637X/813/2/137},
	abstract = {While recent supernova (SN) cosmology research has benefited from improved measurements, current analysis approaches are not statistically optimal and will prove insufficient for future surveys. This paper discusses the limitations of current SN cosmological analyses in treating outliers, selection effects, shape- and color-standardization relations, unexplained dispersion, and heterogeneous observations. We present a new Bayesian framework, called UNITY (Unified Nonlinear Inference for Type-Ia cosmologY), that incorporates significant improvements in our ability to confront these effects. We apply the framework to real SN observations and demonstrate smaller statistical and systematic uncertainties. We verify earlier results that SNe Ia require nonlinear shape and color standardizations, but we now include these nonlinear relations in a statistically well-justified way. This analysis was primarily performed blinded, in that the basic framework was first validated on simulated data before transitioning to real data. We also discuss possible extensions of the method.},
	language = {en},
	number = {2},
	urldate = {2018-10-04},
	journal = {ApJ},
	author = {Rubin, D. and Aldering, G. and Barbary, K. and Boone, K. and Chappell, G. and Currie, M. and Deustua, S. and Fagrelius, P. and {A. Fruchter} and Hayden, B. and Lidman, C. and Nordin, J. and Perlmutter, S. and Saunders, C. and Sofiatti, C. and Project, The Supernova Cosmology},
	year = {2015},
	pages = {137},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/XCT3AG8Y/Rubin et al. - 2015 - UNITY Confronting Supernova Cosmology's Statistic.pdf:application/pdf}
}

@article{ishida_kernel_2013,
	title = {Kernel {PCA} for {Type} {Ia} supernovae photometric classification},
	volume = {430},
	issn = {0035-8711},
	url = {https://academic.oup.com/mnras/article/430/1/509/985966},
	doi = {10.1093/mnras/sts650},
	abstract = {Abstract.  The problem of supernova photometric identification will be extremely important for large surveys in the next decade. In this work, we propose the us},
	language = {en},
	number = {1},
	urldate = {2018-10-04},
	journal = {Mon Not R Astron Soc},
	author = {Ishida, E. E. O. and Souza, De and S, R.},
	month = mar,
	year = {2013},
	pages = {509--532},
	file = {Full Text PDF:/home/aimalz/Documents/References/storage/7HQMT43G/Ishida et al. - 2013 - Kernel PCA for Type Ia supernovae photometric clas.pdf:application/pdf;Snapshot:/home/aimalz/Documents/References/storage/6HG5QETD/985966.html:text/html}
}

@article{jones_measuring_2018,
	title = {Measuring {Dark} {Energy} {Properties} with {Photometrically} {Classified} {Pan}-{STARRS} {Supernovae}. {II}. {Cosmological} {Parameters}},
	volume = {857},
	issn = {0004-637X},
	url = {http://stacks.iop.org/0004-637X/857/i=1/a=51},
	doi = {10.3847/1538-4357/aab6b1},
	abstract = {We use 1169 Pan-STARRS supernovae (SNe) and 195 low- z ( z {\textless} 0.1) SNe Ia to measure cosmological parameters. Though most Pan-STARRS SNe lack spectroscopic classifications, in a previous paper we demonstrated that photometrically classified SNe can be used to infer unbiased cosmological parameters by using a Bayesian methodology that marginalizes over core-collapse (CC) SN contamination. Our sample contains nearly twice as many SNe as the largest previous SN Ia compilation. Combining SNe with cosmic microwave background (CMB) constraints from Planck, we measure the dark energy equation-of-state parameter w to be -0.989 {\textpm} 0.057 (stat+sys). If w evolves with redshift as w ( a) = w 0 + w a(1 - a ), we find w 0 = -0.912 {\textpm} 0.149 and w a = -0.513 {\textpm} 0.826. These results are consistent with cosmological parameters from the Joint Light-curve Analysis and the Pantheon sample. We try four different photometric classification priors for Pan-STARRS SNe and two alternate ways of modeling CC SN contamination, finding that no variant gives a w differing by more than 2\% from the baseline measurement. The systematic uncertainty on w due to marginalizing over CC SN contamination, \#\#IMG\#\# [http://ej.iop.org/images/0004-637X/857/1/51/apjaab6b1ieqn1.gif] \${\textbackslash}sigma \_w{\textasciicircum}{\textbackslash}mathrmCC=0.012\$ , is the third-smallest source of systematic uncertainty in this work. We find limited (1.6 $\sigma$ ) evidence for evolution of the SN color-luminosity relation with redshift, a possible systematic that could constitute a significant uncertainty in future high- z analyses. Our data provide one of the best current constraints on w , demonstrating that samples with \~{}5\% CC SN contamination can give competitive cosmological constraints when the contaminating distribution is marginalized over in a Bayesian framework.},
	language = {en},
	number = {1},
	urldate = {2018-10-04},
	journal = {ApJ},
	author = {Jones, D. O. and Scolnic, D. M. and Riess, A. G. and Rest, A. and Kirshner, R. P. and Berger, E. and Kessler, R. and Pan, Y.-C. and Foley, R. J. and Chornock, R. and Ortega, C. A. and Challis, P. J. and Burgett, W. S. and Chambers, K. C. and Draper, P. W. and {H. Flewelling} and Huber, M. E. and Kaiser, N. and Kudritzki, R.-P. and Metcalfe, N. and Tonry, J. and Wainscoat, R. J. and Waters, C. and Gall, E. E. E. and Kotak, R. and McCrum, M. and Smartt, S. J. and Smith, K. W.},
	year = {2018},
	pages = {51},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/WDRGIJ4A/Jones et al. - 2018 - Measuring Dark Energy Properties with Photometrica.pdf:application/pdf}
}

@article{richards_bayesian_2015,
	title = {Bayesian {High}-redshift {Quasar} {Classification} from {Optical} and {Mid}-{IR} {Photometry}},
	volume = {219},
	issn = {0067-0049},
	url = {http://stacks.iop.org/0067-0049/219/i=2/a=39},
	doi = {10.1088/0067-0049/219/2/39},
	abstract = {We identify 885,503 type 1 quasar candidates to \#\#IMG\#\# [http://ej.iop.org/images/0067-0049/219/2/39/apjs518349ieqn1.gif] \$i{\textbackslash}lesssim 22\$ using the combination of optical and mid-IR photometry. Optical photometry is taken from the Sloan Digital Sky Survey-III: Baryon Oscillation Spectroscopic Survey (SDSS-III/BOSS), while mid-IR photometry comes from a combination of data from the Wide-field Infrared Survey Explorer ( WISE ) {\textquotedblleft}AllWISE{\textquotedblright} data release and several large-area Spitzer Space Telescope fields. Selection is based on a Bayesian kernel density algorithm with a training sample of 157,701 spectroscopically confirmed type 1 quasars with both optical and mid-IR data. Of the quasar candidates, 733,713 lack spectroscopic confirmation (and 305,623 are objects that we have not previously classified as photometric quasar candidates). These candidates include 7874 objects targeted as high-probability potential quasars with \#\#IMG\#\# [http://ej.iop.org/images/0067-0049/219/2/39/apjs518349ieqn2.gif] \$3.5{\textbackslash}lt z{\textbackslash}lt 5\$ (of which 6779 are new photometric candidates). Our algorithm is more complete to \#\#IMG\#\# [http://ej.iop.org/images/0067-0049/219/2/39/apjs518349ieqn3.gif] \$z{\textbackslash}gt 3.5\$ than the traditional mid-IR selection {\textquotedblleft}wedges{\textquotedblright} and to \#\#IMG\#\# [http://ej.iop.org/images/0067-0049/219/2/39/apjs518349ieqn4.gif] \$2.2{\textbackslash}lt z{\textbackslash}lt 3.5\$ quasars than the SDSS-III/BOSS project. Number counts and luminosity function analysis suggest that the resulting catalog is relatively complete to known quasars and is identifying new high- z quasars at \#\#IMG\#\# [http://ej.iop.org/images/0067-0049/219/2/39/apjs518349ieqn5.gif] \$z{\textbackslash}gt 3\$ . This catalog paves the way for luminosity-dependent clustering investigations of large numbers of faint, high-redshift quasars and for further machine-learning quasar selection using Spitzer and WISE data combined with other large-area optical imaging surveys.},
	language = {en},
	number = {2},
	urldate = {2018-10-04},
	journal = {ApJS},
	author = {Richards, Gordon T. and Myers, Adam D. and Peters, Christina M. and Krawczyk, Coleman M. and Chase, Greg and Ross, Nicholas P. and Fan, Xiaohui and Jiang, Linhua and Lacy, Mark and McGreer, Ian D. and Trump, Jonathan R. and Riegel, Ryan N.},
	year = {2015},
	pages = {39},
	file = {IOP Full Text PDF:/home/aimalz/Documents/References/storage/UQCKD866/Richards et al. - 2015 - Bayesian High-redshift Quasar Classification from .pdf:application/pdf}
}

@book{oliphant_python_2007,
	title = {Python for {Scientific} {Computing}},
	volume = {9},
	author = {Oliphant, T.},
	month = may,
	year = {2007},
	doi = {10.1109/MCSE.2007.58}
}

@misc{malz_cosmological_2018,
	title = {Cosmological {Hierarchical} {Inference} with {Probabilistic} {Photometric} {Redshifts}: aimalz/chippr},
	copyright = {MIT},
	shorttitle = {Cosmological {Hierarchical} {Inference} with {Probabilistic} {Photometric} {Redshifts}},
	url = {https://github.com/aimalz/chippr},
	urldate = {2019-04-12},
	author = {Malz, Alex},
	month = jul,
	year = {2018},
	note = {original-date: 2016-12-23T23:41:09Z}
}

@inproceedings{martin_det_1997,
	title = {The {DET} curve in assessment of detection task performance},
	author = {Martin, Alvin F. and Doddington, George R. and Kamm, Terri and Ordowski, Mark and Przybocki, Mark A.},
	year = {1997},
	file = {6f0d7fe2555ed16f405c59ac81eb94a9aec2.pdf:/home/aimalz/Documents/References/storage/GVSSN695/6f0d7fe2555ed16f405c59ac81eb94a9aec2.pdf:application/pdf}
}

@misc{malz_proclam_2018,
	title = {{ProClaM}},
	url = {http://www.github.com/aimalz/proclam},
	author = {Malz, Alex},
	year = {2018},
	doi = {10.5281/zenodo.3352639}
}

@article{buitinck_api_2013,
	title = {{API} design for machine learning software: experiences from the scikit-learn project},
	shorttitle = {{API} design for machine learning software},
	url = {http://arxiv.org/abs/1309.0238},
	abstract = {Scikit-learn is an increasingly popular machine learning li- brary. Written in Python, it is designed to be simple and efficient, accessible to non-experts, and reusable in various contexts. In this paper, we present and discuss our design choices for the application programming interface (API) of the project. In particular, we describe the simple and elegant interface shared by all learning and processing units in the library and then discuss its advantages in terms of composition and reusability. The paper also comments on implementation details specific to the Python ecosystem and analyzes obstacles faced by users and developers of the library.},
	urldate = {2019-07-27},
	journal = {arXiv:1309.0238 [cs]},
	author = {Buitinck, Lars and Louppe, Gilles and Blondel, Mathieu and Pedregosa, Fabian and Mueller, Andreas and Grisel, Olivier and Niculae, Vlad and Prettenhofer, Peter and Gramfort, Alexandre and Grobler, Jaques and Layton, Robert and Vanderplas, Jake and Joly, Arnaud and Holt, Brian and Varoquaux, Ga{\"e}l},
	month = sep,
	year = {2013},
	note = {arXiv: 1309.0238},
	keywords = {Computer Science - Machine Learning, Computer Science - Mathematical Software},
	file = {arXiv\:1309.0238 PDF:/home/aimalz/Documents/References/storage/4LSFCM9Z/Buitinck et al. - 2013 - API design for machine learning software experien.pdf:application/pdf;arXiv.org Snapshot:/home/aimalz/Documents/References/storage/HCWMWYR2/1309.html:text/html}
}